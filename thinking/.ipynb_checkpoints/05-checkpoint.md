### Thinking

**1. 什么是矩阵分解，都有哪些应用场景？**

推荐系统的两大应用场景包括评分预测和Top-N推荐，其中矩阵分解的技术主要在于评分预测问题。主要是利用评分矩阵来分解User矩阵和Item矩阵的过程。其是隶属于基于模型的协同过滤技术。

推荐系统的评分预测问题可以看成是一个矩阵不全的过程，矩阵补全是推荐系统的任务，矩阵分解使其达到目的的手段。其中具体的技术如下所示：

- PureSVD（奇异值分解）

![](imgs/th-5-1.png)

SVD分解的形式为3个矩阵相乘，左右两个矩阵分别表示user/item隐含因子矩阵，中间矩阵为奇异值矩阵并且是对角矩阵，每个元素满足非负性，并且逐渐减小，因此只需要前k个元素表示即可。

其中SVD的使用条件，即要求矩阵是稠密的，矩阵的元素要非空，否则就不能使用SVD，所以一般先使用均值或者其他统计学方式来填充矩阵，然后利用SVD分解，其主要利用于降维方面。

- FunkSVD

使用SVD分解技术需要进行矩阵乘法（复杂度为O(n^3)）上述三个矩阵之间需要做两次矩阵乘法,存在计算复杂度高的问题。因此在这个基础上，FunkSVD不在将矩阵分解为3个矩阵，而是分解为2个低秩的user/item矩阵，同时降低了计算的复杂度 

![](imgs/th-5-2.png)

为了避免过拟合，又提出了带有L2正则项的FunkSVD

![](imgs/th-5-3.png)

- PMF (Probabilistic matrix factorization)

PMF是对于FunkSVD的概率解释版本，它假设评分矩阵种的元素$R_{ij}$是由用户潜在偏好向量$U_i$和物品潜在属性向量$V_j$的内积决定的，并且服从均值为$U_i^TV_j$，方差为$\phi^2$的正太分布

![](imgs/th-5-4.png)

详细推导见[link](https://zhuanlan.zhihu.com/p/35262187)

- BiasSVD

BiasSVD基于user/item本身就会自带一些天然的特质这个假设，提出了user/item偏置项

![](imgs/th-5-6.png)

优化目标为![](imgs/th-5-7.png)



- SVD++

基于上述的隐式评分外，隐式反馈信息同样有助于用户的偏好建模。它是建立于：用户除了对项目的显式历史评分记录外，浏览记录或者收藏列表等隐反馈信息同时可以从侧面一定程度上反映用户的偏好

![](imgs/th-5-8.png)

- timeSVD

假设：用户的兴趣或者偏好不是一成不变的，而是随着时间而动态演化。于是提出了timeSVD，其中user和item的偏置随着时间变化，同时user的隐含因子也随着时间而动态变化，在此物品的隐含表示并未随着时间而变化（其中物品的属性不会随着时间而改变）

![](imgs/th-5-9.png)

其中,t为时间因子表示不同的时间状态。

**2. 矩阵分解算法ALS-WR是如何进行的？**

ALS-WR（Alternating-Least-Squares with Weighted-lambda-Regularization）,其来源于Large-scale Parallel Collaborative Filtering for the Netflix Prize，在Netflix Prize数据集上的RSME高达0.8985。其也是种基于协同过滤的算法，其执行步骤主要分为如下四步，其中记item矩阵为M，user矩阵为U，这两个矩阵为ALS-WR要求解的矩阵，还有一个已知评分矩阵R，目标函数![](imgs/ths-5-11.png)

其中$n_{u_i}$和$n_{m_j}$分别表示user $i$ 和 item $j$ 的评分数量，即user对多少item进行了评分，item被多少用户进行了评分。$I_i$表示用户$i$的评分的电影集合，$n_{u_i}$为其中的候选集合，同样的$I_j$表示评分电影$j$的用户集合，$n_{m_j}$为其候选集合。上式的第一项表示求解值和真实值的sum of square error，第二项表示正则项，其中第一式子表示每个用户$i$对评分电影集合$I_i$的矩阵加权$n_{u_i}$乘积，第二个式子表示每个电影$j$对用户集合$I_j$的矩阵加权$n_{m_j}$的乘积。

- 初始化矩阵M的第1行通过平均评分来进行初始化，其他的行通过随机化一个小数。
- 固定M，通过最小化目标函数求解U
- 固定U，同样通过最小化目标函数来求解M
- 重复步骤2和3直到条件满足（迭代次数，目标函数变化程度）

求解的结果如下：

![](imgs/th-5-12.png)

其中$A_i=M_{I_i}M_{I_i}^T+\lambda n_{u_i}$，$V_i=M_{I_i}R^T(i, I_i)$，$E$是一个$n_f \times n_f$的矩阵，$M_{I_i}$表示一个子矩阵，其中$I_i$是一个列集合，表示评分item集合。同理，$I_j$表示user集合（对电影$j$进行评分）。

上式的直观解释：求解$U$需要对每个user $i$进行求导，即上式仅是求解了U的一行。基于这个考虑，ALS-WR可以实现**并行计算**，可以让每个节点同时计算上式，然后组装成$U$供求解$M$使用，即上面的计算可以缩减为计算一次，但是计算$U$和$M$并不能够并行，由于计算一个$u_i$需要所有的$m_j$。

同理，$m_j=A_j^{-1}V_j$,因为是对称的。

**进阶** 引入隐式因子，进一步robust和加速训练过程

![](imgs/th-5-13.png)

![](imgs/th-5-14.png)

对于上边的个人理解，降低对评分高的Item的损失，和Adaboost中通过调整分类误差率小的基本分类器权重有相似之处，对于评分矩阵中评分越高，Loss函数对其的关注度越大。最终的求解结果如下

![](imgs/th-5-15.png)

**3. 梯度下降法中的批量梯度下降（BGD），随机梯度下降（SGD）、和小批量梯度下降有什么区别（MBGD）**

![](imgs/th-5-16.png)

上式是随机梯度下降，每次使用一个样本损失进行更新，而BGD使用所有的样本损失进行更新，MBGD是基于两者之间的一种方式，每次利用部分的样本损失值进行更新，其中部分样本的生成可以采用把原始样本进行均分成多分放入迭代函数中，也可以采用抽样的方式等。

**4. 推荐系统中的冷启动都有哪些情况，有哪些常用的解决方法？**

常见的冷启动问题包括物品冷启动、用户冷启动、系统冷启动。

- 用户冷启动

  - 提供非个性化推荐，可以利用Hot item，人工指定策略（处理MAB问题的算法bandit）,提供多样性（试探性的EE探索）
  - 利用注册信息进行学习，如基本的用户信息，注册时选择的兴趣点或者方向，利用基本信息（通讯录等）查找好友，利用好友的偏好进行推荐。
  - 当user和系统进行交互，利用交互信息动态的做推荐（强化学习基于无监督的动态调整策略）
  - 兴趣迁移，对应同一个用户不同平台之间的信息共享，转化为迁移学习的问题范式。

- 系统冷启动

  - 同样可以利用注册信息
  - 利用强化学习，基于内容本身的反馈信息获得相应的推荐，也可以做实时的在线推荐。
  - 打通数据中台，建立完整的用户画像，让多个系统之间的用户画像可迁移。

- 物品冷启动

  - 快速试探策略即Bandit类算法，可以用新闻、短视频类，对刚刚上传的item，可以试探性的推荐给user,若user做出正向反应，则可以表示用户对此有兴趣，反之没有。
  - 利用商品的元信息查找item和item之间的相似性，做推荐；利用item与用户行为的相似性，做推荐。[关系传递的策略]

  可以基于Item的属性信息来做推荐，一般新上线的商品都会有一些属性，根据这些属性找到与最相似的商品，这些相似的商品被哪些用户“消费”过，可以将该item推荐给这些消费过的用户。

**5. 阅读的推荐系统相关或者机器学习相关的论文**

![](imgs/th-5-17.png)

现在比较先进的推荐算法是基于CTR的深度模型。其中主要处理是利用CNN对输入的向量进行学习，此时如何构造这个输入的向量的算法包括CCPM，FNN, pnn, fgcnn, fibinet, nfm等，如何有效的学习/充分挖掘高阶特征，如模型DeepFM，xDeepFM，DCN，AutoInt和AFM等