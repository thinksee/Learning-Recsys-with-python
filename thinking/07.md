### Thinking

**1. 在实际工作中，FM和MF哪个应用的更多，为什么**

FM使用的较多。其中MF仅考虑了UserID和ItemID的特征，但是在实际过程中需要考虑的特征维度不仅仅这两个；MF仅是考虑了预测评分问题，但是若涉及回归和分类问题，MF无能为力了；而FM考虑了更多维度的特征，以及二阶特征组合，可以作为一个通用的回归和分类算法模型。

**2. FFM与FM有哪些区别？**

- FFM引入了field的概念，若field个数为1则，FFM就是FM，可以认为FM是特殊的FFM。
- 在表示方面，FM都有唯一的一个embedding向量，而FFM有field的个数的embedding向量。
- 在模型参数方面，若embedding向量维度为k，则FFM有nfk个参数，而FM有nk个参数。
- 计算复杂度方面，FM优化可以把复杂度降低为kn，而FFM为kn*n。
- 从宏观上看，FFM的每个embedding向量是借助field进行一次加权平均，而FM则没有，其中field的个数很大程度上需要人工介入。

**3. DeepFM相比于FM解决了哪些问题，原理是怎样的**

- FM仅考虑到了二阶特征，而DeepFM考虑了高阶特征。
- FM需要进行手工特征，而DeepFM利用DNN可以捕获特征相当于一个特征提取器。

其具体原理”DeepFM=FM+DNN“来构成。使用FM模型进行低阶特征提取，使用end-to-end的DNN网络进行高阶特征提取，其中每个feature的embedding向量之间共享特征，而每个field中每个feature共享权重。最后的结果为FM与DNN结果之和，然后通过sigmoid函数求出要预测的值。

**4. 假设一个小说网站，有N部小说，每部小说都有摘要描述。如何针对该网站制定基于内容的推荐系统，即用户看了某部小说后，推荐其他相关的小说。原理和步骤是怎样的**

基本原理是借助了文本内容的相似性，操作如下：

- 摘要关键词提取（提取方式可以采用TF-IDF作为baseline）
- NLP的基本流程，建立词典，利用one-hot或者word2vec求得每部小说的embedding向量
- 借助余弦相似度计算每部小说embedding向量之间的相似度关系
- 引入其他额外条件（如热销、打折等买卖信息以及用户的基本偏好）打散推荐列表（列表可以取相似度最接近的top-k）

**5. Word2Vec的应用场景有哪些**

- 用来做词向量embedding
- 把其他问题（社交网络推荐、商品相似度、模型的输入，文档检索以及搜索）转化为词向量embedding求解问题

