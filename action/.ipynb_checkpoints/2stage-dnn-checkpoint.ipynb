{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用DNN模型的两阶段主要是参考Youtube视频推荐系统“Recommending What Video to Watch Next: A Multitask Ranking System”\n",
    "### 召回\n",
    "把推荐问题看成是一个“超大规模多分类”问题。即在时刻$t$，为用户$U$（上下文信息$C$）在视频库$V$中精确的预测出视频$i$的类别（每个具体的视频视为一个类别，$i$即为一个类别），用数学公式表达如下：\n",
    "$$P(w_t = i | U,C) = \\frac{e^{v_iu}}{\\sum_{j \\in V} e^{v_j}u}$$。\n",
    "向量$U \\in R^N$是<user, context>信息的高维“embedding”，而向量$v_j \\in R^N$则是视频$j$的embedding向量。所以DNN的目标就是在用户信息和上下文信息为输入条件下学习用户的embedding向量$u$。用公式表达DNN就是在拟合函数$u=f_{DNN}(user_{info}, context_{infor})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/youtube1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入\n",
    "其中输入包括embedding的video和search向量，还有地理（geographic）向量，视频新鲜度（example age）向量以及性别（gender）向量。\n",
    "\n",
    "类似于word2vec的做法，每个视频都会被embedding到固定维度的向量中。用户的观看视频历史则是通过变长的视频序列表达，最终通过加权平均（可根据重要性和时间进行加权）得到固定维度的watch vector作为DNN的输入。\n",
    "\n",
    "- 使用更广的数据源：不仅仅使用推荐场景的数据进行训练，其他场景比如搜索等的数据也要用到，这样也能为推荐场景提供一些explore。\n",
    "- 为每个用户生成固定数量训练样本：我们在实际中发现的一个practical lessons，如果为每个用户固定样本数量上限，平等的对待每个用户，避免loss被少数active用户domanate，能明显提升线上效果。\n",
    "- 抛弃序列信息：我们在实现时尝试的是去掉序列信息，对过去观看视频/历史搜索query的embedding向量进行加权平均。这点其实违反直觉，可能原因是模型对负反馈没有很好的建模。\n",
    "- 不对称的共同浏览（asymmetric co-watch）问题：所谓asymmetric co-watch值的是用户在浏览视频时候，往往都是序列式的，开始看一些比较流行的，逐渐找到细分的视频。下图所示图(a)是hled-out方式，利用上下文信息预估中间的一个视频；图(b)是predicting next watch的方式，则是利用上文信息，预估下一次浏览的视频。\n",
    "\n",
    "![](imgs/youtube2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图反映了不同网络深度（横坐标）下不同特征组合情况下的holdout-MAP（纵坐标）。可以很明显看出，增加了观看历史之外的特征很明显的提升了预测得准确率；从网络深度看，随着网络深度加大，预测准确率在提升，但继续增加第四层网络已经收益不大了。\n",
    "\n",
    "![](imgs/youtube3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输出\n",
    "召回的输出为用户的embedding向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排序\n",
    "\n",
    "Ranking阶段的最重要任务就是精确的预估用户对视频的喜好程度。不同于Matching阶段面临的是百万级的候选视频集，Ranking阶段面对的只是百级别的商品集，因此需要使用更多更精细的feature来刻画视频以及用户与视频之间的关系。如用户可能很喜欢某个视频，但若List页面用的缩略图选择不当，用户也许不会点击等等。\n",
    "\n",
    "此外，Matching阶段的来源往往很多，没法直接比较。Ranking阶段另一个关键的作用是能够把不同来源的数据进行有效的ensemble。\n",
    "\n",
    "在目标的设定方面，单纯的CTR指标是有迷惑性的，有些考关键词吸引用户高点击的视频未必能够被播放。因此设定的目标基本与期望的观看时长相关，具体的目标调整则根据线上的A/B测试。\n",
    "\n",
    "\n",
    "**模型架构**\n",
    "\n",
    "Ranking阶段的模型和召回基本相似，不同的是training最后一层是一个weighted LR层，而serving阶段激励函数作用用的是$e^x$。\n",
    "\n",
    "![](imgs/youtube4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入\n",
    "- Feature Engineering\n",
    "\n",
    "尽管深度学习在图像、语音和NLP等场景都能实现end-to-end的训练，没有了人工特征工程工作。然而在搜索和推荐场景，我们的很难吧原始数据直接作为FNN的输入，特征工程仍然很重要。而特征工程中最难的是如何建模用户时序行为（temporal sequence of user actions），并且关联这些行为和要rank的item。\n",
    "\n",
    "我们发现最重要的Signal是描述用户与商品本身或相似商品之间交互的Signal，这与Facebook在14年提出LR+GBDT模型的paper（Practical Lessons from Predicting Clicks on Ads at Facebook）中得到的结论是一致的。比如我们要度量用户对视频的喜欢，可以考虑用户与视频所在频道间的关系：\n",
    "\n",
    ">数量特征：浏览该频道的次数？\n",
    "\n",
    ">时间特征：比如最近一次浏览该频道距离现在的时间？\n",
    "\n",
    "这两个连续特征的最大好处是具备非常强的泛化能力。另外除了这两个偏正向的特征，用户对于视频所在频道的一些PV但不点击的行为，即负反馈Signal同样非常重要。\n",
    "\n",
    "\n",
    "\n",
    "另外，我们还发现，把Matching阶段的信息传播到Ranking阶段同样能很好的提升效果，比如推荐来源和所在来源的分数。\n",
    "\n",
    "- Embedding Categorical Features\n",
    "\n",
    "NN更适合处理连续特征，因此稀疏的特别是高基数空间的离散特征需要embedding到稠密的向量中。每个维度（比如query/user_id）都有独立的embedding空间，一般来说空间的维度基本与log(去重后值得数量)相当。实际并非为所有的id进行embedding，比如视频id，只需要按照点击排序，选择top N视频进行embedding，其余置为0向量。而对于像“过去点击的视频”这种multivalent特征，与Matching阶段的处理相同，进行加权平均即可。\n",
    "\n",
    "另外一个值得注意的是，同维度不同feature采用的相同ID的embedding是共享的（比如“过去浏览的视频id” “seed视频id”），这样可以大大加速训练，但显然输入层仍要分别填充。\n",
    "\n",
    "- Normalizing Continuous Features\n",
    "\n",
    "众所周知，NN对输入特征的尺度和分布都是非常敏感的，实际上基本上除了Tree-Based的模型（比如GBDT/RF），机器学习的大多算法都如此。我们发现归一化方法对收敛很关键，推荐一种排序分位归一到[0,1]区间的方法，即$x$为$x$到负无穷的累计分位点。\n",
    "\n",
    "除此之外，我们还把归一化后的$\\bar{x}$的根号$\\sqrt{x}$和平方$x^2$作为网络输入，以期能使网络能够更容易得到特征的次线性（sub-linear）和（super-linear）超线性函数。\n",
    "\n",
    "#### 输出\n",
    "\n",
    "我们的目标是预测期望观看时长。有点击的为正样本，有PV无点击的为负样本，正样本需要根据观看时长进行加权。因此，我们训练阶段网络最后一层用的是 weighted logistic regression。\n",
    "\n",
    "正样本的权重为观看时长 $T_i$，负样本权重为1。这样的话，LR学到的odds为：\n",
    "$$\\frac{\\sum T_i}{N - k}$$\n",
    "其中$N$是总的样本数量，$k$是正样本数量，$T_i$是第$i$正样本的观看时长。一般来讲，k相对于N比较小，因此上式的odds可以转化成$E[T]/(1+P)$，其中$P$是点击率，点击率一般很小，这样odds接近于$E[T]$，即期望观看时长。因此在线上serving的inference阶段，我们采用$e^x$作为激励函数，就是近似估计期望的观看时长。\n",
    "\n",
    "![](imgs/youtube5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
