{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 108])\n",
    "y = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "learning_rate = 0.3\n",
    "w = tf.Variable(tf.random_normal([108, m], 0.0, 0.5), name='u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.matmul(x, w)\n",
    "p2 = tf.reduce_sum(tf.nn.sigmoid(w), 1)  # \n",
    "pred = p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "cost1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y))  # 损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.add_n([cost1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.FtrlOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_data():\n",
    "    train_data = pd.read_table(\"../dataset/adult/adult.data\",header=None,delimiter=',')\n",
    "    test_data = pd.read_table(\"../dataset/adult/adult.test\",header=None,delimiter=',')\n",
    "\n",
    "    all_columns = ['age','workclass','fnlwgt','education','education-num',\n",
    "                        'marital-status','occupation','relationship','race','sex',\n",
    "                        'capital-gain','capital-loss','hours-per-week','native-country','label','type']\n",
    "\n",
    "    continus_columns = ['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "    dummy_columns = ['workclass','education','marital-status','occupation','relationship','race','sex','native-country']\n",
    "\n",
    "    train_data['type'] = 1\n",
    "    test_data['type'] = 2\n",
    "\n",
    "    all_data = pd.concat([train_data,test_data],axis=0)\n",
    "    all_data.columns = all_columns\n",
    "\n",
    "    all_data = pd.get_dummies(all_data,columns=dummy_columns)\n",
    "\n",
    "\n",
    "    test_data = all_data[all_data['type']==2].drop(['type'],axis=1)\n",
    "    train_data = all_data[all_data['type']==1].drop(['type'],axis=1)\n",
    "\n",
    "    train_data['label'] = train_data['label'].map(lambda x: 1 if x.strip() == '>50K' else 0)\n",
    "    test_data['label'] = test_data['label'].map(lambda x: 1 if x.strip() == '>50K.' else 0)\n",
    "\n",
    "\n",
    "    for col in continus_columns:\n",
    "        ss = StandardScaler()\n",
    "        train_data[col] = ss.fit_transform(train_data[[col]])\n",
    "        test_data[col] = ss.transform(test_data[[col]])\n",
    "\n",
    "\n",
    "    train_y = train_data['label']\n",
    "    train_x = train_data.drop(['label'],axis=1)\n",
    "    test_y = test_data['label']\n",
    "    test_x = test_data.drop(['label'],axis=1)\n",
    "\n",
    "    return train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "train_x,train_y,test_x,test_y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 0.6674295\n",
      "cost 0.6674265\n",
      "cost 0.66742367\n",
      "cost 0.66742074\n",
      "cost 0.6674179\n",
      "cost 0.66741514\n",
      "cost 0.66741234\n",
      "cost 0.6674095\n",
      "cost 0.66740674\n",
      "cost 0.6674041\n",
      "cost 0.66740143\n",
      "cost 0.6673987\n",
      "cost 0.667396\n",
      "cost 0.66739345\n",
      "cost 0.6673909\n",
      "cost 0.66738826\n",
      "cost 0.6673858\n",
      "cost 0.6673833\n",
      "cost 0.6673808\n",
      "cost 0.6673784\n",
      "cost 0.66737586\n",
      "cost 0.66737336\n",
      "cost 0.667371\n",
      "cost 0.6673686\n",
      "cost 0.66736627\n",
      "cost 0.667364\n",
      "cost 0.66736174\n",
      "cost 0.6673595\n",
      "cost 0.66735715\n",
      "cost 0.6673549\n",
      "cost 0.6673527\n",
      "cost 0.6673505\n",
      "cost 0.66734827\n",
      "cost 0.6673461\n",
      "cost 0.667344\n",
      "cost 0.6673419\n",
      "cost 0.6673397\n",
      "cost 0.66733766\n",
      "cost 0.6673356\n",
      "cost 0.66733354\n",
      "cost 0.6673315\n",
      "cost 0.6673295\n",
      "cost 0.6673275\n",
      "cost 0.66732556\n",
      "cost 0.66732365\n",
      "cost 0.66732174\n",
      "cost 0.6673198\n",
      "cost 0.6673178\n",
      "cost 0.66731596\n",
      "cost 0.6673141\n",
      "cost 0.6673122\n",
      "cost 0.6673104\n",
      "cost 0.6673085\n",
      "cost 0.6673068\n",
      "cost 0.667305\n",
      "cost 0.6673032\n",
      "cost 0.6673015\n",
      "cost 0.6672997\n",
      "cost 0.6672979\n",
      "cost 0.6672963\n",
      "cost 0.6672947\n",
      "cost 0.6672929\n",
      "cost 0.6672913\n",
      "cost 0.6672895\n",
      "cost 0.6672878\n",
      "cost 0.6672863\n",
      "cost 0.6672846\n",
      "cost 0.66728294\n",
      "cost 0.6672815\n",
      "cost 0.66727984\n",
      "cost 0.66727823\n",
      "cost 0.6672768\n",
      "cost 0.6672752\n",
      "cost 0.66727364\n",
      "cost 0.66727227\n",
      "cost 0.66727066\n",
      "cost 0.6672692\n",
      "cost 0.6672678\n",
      "cost 0.6672663\n",
      "cost 0.6672648\n",
      "cost 0.6672634\n",
      "cost 0.6672619\n",
      "cost 0.66726047\n",
      "cost 0.6672591\n",
      "cost 0.6672577\n",
      "cost 0.66725624\n",
      "cost 0.667255\n",
      "cost 0.66725355\n",
      "cost 0.66725224\n",
      "cost 0.667251\n",
      "cost 0.66724956\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "time_s = time.time()\n",
    "for epoch in range(0, 10000):\n",
    "    f_dict = {x: train_x, y:train_y}\n",
    "    _, _cost, _predict = sess.run([train_op, cost, pred], feed_dict=f_dict)\n",
    "    auc = roc_auc_score(train_y, _predict)\n",
    "    time_t=time.time()\n",
    "    if epoch % 100 == 0:\n",
    "        f_dict = {x: test_x, y: test_y}\n",
    "        _, _cost, predict_test = sess.run([train_op, cost, pred], feed_dict=f_dict)\n",
    "        print('cost', _cost)\n",
    "        test_auc = roc_auc_score(test_y, predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
