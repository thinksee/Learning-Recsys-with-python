{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**线性回归**\n",
    "\n",
    "- 损失函数\n",
    "$$J(\\theta) = \\frac{1}{2}(\\bar{y}_i - y_i)^2 = \\frac{1}{2} \\sum_{i=1}^n (h_{\\theta}(x_i) - y_i)^2$$\n",
    "\n",
    "- 引入矩阵运算\n",
    "$$J(\\theta) = \\frac{1}{2} (X \\theta - Y)^T (X \\theta - Y) = \\frac{1}{2}(\\theta ^ T X^T - Y^T)(X \\theta - Y)=\\frac{1}{2} (\\theta ^ T X^T X \\theta - 2\\theta ^T X^T Y + Y^T Y)$$\n",
    "\n",
    "- 矩阵求导运算\n",
    "$$\\frac{dAB}{dB} = A^T$$\n",
    "\n",
    "$$\\frac{dA^TB}{A} = B$$\n",
    "\n",
    "$$\\frac{dX^T AX}{dX} = 2AX$$\n",
    "\n",
    "- 对$\\theta$进行求导\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta} = \\frac{1}{2} (2X^TX \\theta - 2X^T \\theta)=X^TX \\theta - X^TY$$\n",
    "\n",
    "- 令 $\\frac{\\partial J(\\theta)}{\\partial \\theta} = 0$\n",
    "\n",
    "- 可以得到\n",
    "\n",
    "$$\\theta = (X^TX)^{-1}X^T Y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        \"\"\"\n",
    "        最小二乘回归模型\n",
    "        参数：\n",
    "        @ fit_intercept : bool\n",
    "            截距是否存在即线性函数是否含有b\n",
    "        \"\"\"\n",
    "        self.beta = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        通过极大似然拟合回归系数\n",
    "        参数：\n",
    "        @X : 形状大小为'(N, M)'，即N个样本，每个样本M个维度\n",
    "        @y ：形状大小为'(N, K)'，即N个样本，每个target有K维\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]  # 添加1列到X中，作为偏置/截距的系数\n",
    "            \n",
    "        pseudo_inverse = np.dot(np.linalg.inv(np.dot(X.T, X)), X.T)\n",
    "        self.beta = np.dot(pseudo_inverse, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        用生成的模型预测\n",
    "        参数：\n",
    "        @X : 数据形状为'(Z, M)'，即数据集是由Z个样本组成，样本维度为M\n",
    "        返回值：\n",
    "        @y_pred = 数据形状为'(Z, K)'\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        return np.dot(X, self.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge回归**\n",
    "\n",
    "在线性回归的基础上，加入了'l2'惩罚项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, alpha=1, fit_intercept=True):\n",
    "        self.beta = None\n",
    "        self.alpha = alpha\n",
    "        self.fit_intercept = fit_intercept\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        \n",
    "        A = self.alpha * np.eye(X.shape[1])\n",
    "        pseudo_inverse = np.dot(np.linalg.inv(X.T @ X + A), X.T)\n",
    "        self.beta = pseudo_inverse @ y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        return np.dot(X, self.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logisitic Regression** 的基本函数为sigmoid函数，即$\\frac{1}{1+e^{-z}}$。\n",
    "\n",
    "其中线性函数定义为: $z_{\\theta}(x)=\\theta_0x_0 + \\theta_1 x_1 + \\cdots + \\theta_n x_n = \\theta^T x$，逻辑回归函数是在线性函数的基础上添加了一个非线性映射，即\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+e^{-z_{\\theta}(x)}} = \\frac{1}{1+e^{-\\theta^Tx}}$$\n",
    "\n",
    "对于二分类来讲，用$\\theta$来表示为正样本的概率即，\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+e^{-z_{\\theta}(x)}}=\\frac{1}{1+e^{-\\theta^Tx}}$$\n",
    "同理，表示负样本为：\n",
    "$$h_{\\theta}(x)=\\frac{e^{-z_{\\theta}(x)}}{1+e^{-z_{\\theta}(x)}}=\\frac{e^{-\\theta^Tx}}{1+e^{-\\theta^Tx}}$$\n",
    "\n",
    "通常，利用阈值进行正负样本的预测或者多分类问题即 $\\bar{y}=1$ if $\\bar{h} \\geq 0.5$, and $y = 0$ if $\\bar{h} < 0.5$. The **decision boundary** is given by $\\theta^T \\cdot x=0$. \n",
    "\n",
    "逻辑回归的损失函数为logloss或者交叉熵损失函数:\n",
    "$$J(\\theta)=-\\frac{1}{m} \\sum_{i=1}^m[y^{(i)}log(h_{\\theta}^{(i)})+(1-y^{(i)})log(1-h_{\\theta}^{(i)})]$$\n",
    "求导之后的损失:\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j}=\\frac{1}{m}\\sum_{i=1}^m(h^{(i)}-y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "手动推导:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "h^{\\prime} &= (\\frac{1}{1+e^{-\\theta^Tx}})^{\\prime} \\\\\n",
    "& = - \\frac{1}{(1+e^{-\\theta^Tx})^2} \\cdot (1+e^{-\\theta^Tx})^{\\prime} \\\\\n",
    "& = - \\frac{1}{(1+e^{-\\theta^Tx})^2} \\cdot e^{-\\theta^Tx} \\cdot (-\\theta^Tx)^{\\prime} \\\\\n",
    "& = - \\frac{xe^{-\\theta^Tx}}{(1+e^{\\theta^Tx})^2} \\\\\n",
    "& = - \\frac{1}{1+e^{-\\theta^Tx}} \\cdot \\frac{e^{-\\theta^Tx}}{1+e^{-\\theta^Tx}} \\cdot x \\\\\n",
    "& = h(1-h)x\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "J(\\theta)^{\\prime} &= \\sum_{i=1}^m(y_i log^{\\prime}(h) + (1-y_i)log^{\\prime}(1-h))) \\\\\n",
    "& = \\sum ((y_i\\frac{1}{h}h^{\\prime})+(1-y_i)\\frac{1}{1-h}(1-h)^{\\prime}) \\\\\n",
    "& = \\sum (y_i (1-h)x_i - (1-y_i)hx_i )\\\\\n",
    "& = \\sum (y_i-h)x_i\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "where $i$ means $i$-th sample, and $j$ means $j$-th feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, penalty='l2', gamma=0, fit_intercept=True):\n",
    "        err_msg = \"penalty must be 'l1' or 'l2', but got: {}\".format(penalty)\n",
    "        assert penalty in ['l1', 'l2'], err_msg\n",
    "        \n",
    "        self.beta = None\n",
    "        self.gamma = gamma\n",
    "        self.penalty = penalty\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def fit(self, X, y, lr=0.01, tol=1e-7, max_iter=1e7):\n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        \n",
    "        l_prev = np.inf\n",
    "        \n",
    "        self.beta = np.random.rand(X.shape[1])\n",
    "        for _ in range(int(max_iter)):\n",
    "            y_pred = sigmoid(np.dot(X, self.beta))\n",
    "            loss = self._NLL(X, y, y_pred)\n",
    "            if l_prev - loss < tol:\n",
    "                return\n",
    "            l_prev = loss\n",
    "            self.beta -= self.lr * self._NLL_grad(X, y, y_pred)\n",
    "            \n",
    "    def _NLL(self, X, y, y_pred):\n",
    "        N, M = X.shape\n",
    "        order = 2 if self.penalty == 'l2' else 1\n",
    "        nll = -np.log(y_pred[y==1]).sum() - np.log(1-y_pred[y==0]).sum()\n",
    "        penalty = 0.5 * self.gamma * np.linalg.norm(self.beta, ord=order) ** 2\n",
    "        return (nll + penalty) / N\n",
    "    \n",
    "    def _NLL_grad(self, X, y, y_pred):\n",
    "        N, M = X.shape\n",
    "        p = self.penalty\n",
    "        beta = self.beta\n",
    "        gamma = self.gamma\n",
    "        \n",
    "        l1norm = lambda x : np.linalg.norm(x, 1)\n",
    "        d_penalty = gamma * beta if p == 'l2' else gamma * l1norm(beta) * np.sign(beta)  # 绝对值求导 https://www.zhihu.com/question/276554773\n",
    "        return -(np.dot(y - y_pred, X) + d_penalty) / N \n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        return sigmoid(np.dot(X, self.beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
