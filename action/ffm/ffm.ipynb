{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_size = 20\n",
    "field_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dimension = 3\n",
    "total_plan_train_steps = 1000\n",
    "batch_size = 1\n",
    "all_data_size = 1000\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'TFModel'\n",
    "MODEL_NAME = 'FFM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFM**\n",
    "\n",
    "$$y(x) = w_0 + \\sum_{i=1}^d w_ix_i + \\sum_{i=1}^d \\sum_{j=i+1}^d (w_{i, f_j} \\cdot w_{j,f_i}) x_i x_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create2dim_weight(input_x_size, field_size, vector_dimension):\n",
    "    weights = tf.truncated_normal([input_x_size, field_size, vector_dimension])\n",
    "    tf_weights = tf.Variable(weights)\n",
    "    return tf_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create1dim_weight(input_x_size):\n",
    "    weights = tf.truncated_normal([input_x_size])\n",
    "    tf_weights = tf.Variable(weights)\n",
    "    return tf_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create0dim_weight(input_x_size):\n",
    "    weights = tf.truncated_normal([1])\n",
    "    tf_weights = tf.Variable(weights)\n",
    "    return tf_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imgs/reduce_sum.png)\n",
    "``` python\n",
    "x = [\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1]\n",
    "]\n",
    "tf.reduce_sum(x) => 6\n",
    "tf.reduce_sum(x, 0) => [2, 2, 2]\n",
    "tf.reduce_sum(x, 1) => [3, 3]\n",
    "tf.reduce_sum(x, 1, keep_dims=True) => [[3], [3]]\n",
    "tf.reduce_sum(x, [0, 1]) => 6\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.gather_nd**\n",
    "\n",
    "允许在多维上进行索引\n",
    "matrix中直接通过坐标取数（索引维度和tensor维度相同）\n",
    "\n",
    "**通过索引直接取数**\n",
    "``` python\n",
    "indices = [[0, 0], [1, 1]]\n",
    "params = [['a', 'b'], ['c', 'd']]\n",
    "output = ['a', 'd']\n",
    "```\n",
    "\n",
    "**取第1行和第2行**\n",
    "```python\n",
    "indices = [[1], [0]]\n",
    "params = [['a', 'b'], ['c', 'd']]\n",
    "output = [['c', 'd'], ['a', 'b']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_x, input_x_field, zero_weights, one_dim_weights, third_weight):\n",
    "    # 计算回归模型预测值\n",
    "    second_value = tf.reduce_sum(tf.multiply(one_dim_weights, input_x, name='second_value'))\n",
    "    first_second_value = tf.add(zero_weights, second_value, name='first_second_value') \n",
    "    third_value = tf.Variable(0.0, dtype=tf.float32)\n",
    "    input_shape = input_x_size\n",
    "    for i in range(input_shape):\n",
    "        feature_index1 = i\n",
    "        field_index1 = int(input_x_field[i])\n",
    "        for j in range(i+1, input_shape):\n",
    "            feature_index2 = j\n",
    "            field_index2 = int(input_x_field[j])\n",
    "            vector_left = tf.convert_to_tensor([[feature_index1, field_index2, i] for i in range(vector_dimension)])\n",
    "            weight_left = tf.gather_nd(third_weight, vector_left)\n",
    "            weight_left_after_cut = tf.squeeze(weight_left)  # 删除为1的维度\n",
    "            \n",
    "            vector_right = tf.convert_to_tensor([[feature_index2, field_index1, i] for i in range(vector_dimension)])\n",
    "            weight_right = tf.gather_nd(third_weight, vector_right)\n",
    "            weight_right_after_cut = tf.squeeze(weight_right)\n",
    "            \n",
    "            tmp_value = tf.reduce_sum(tf.multiply(weight_left_after_cut, weight_right_after_cut))\n",
    "            \n",
    "            indices2 = [i]\n",
    "            indices3 = [j]\n",
    "            \n",
    "            xi = tf.squeeze(tf.gather_nd(input_x, indices2))\n",
    "            xj = tf.squeeze(tf.gather_nd(input_x, indices3))\n",
    "            \n",
    "            product = tf.reduce_sum(tf.multiply(xi, xj))\n",
    "            second_item_val = tf.multiply(tmp_value, product)\n",
    "            \n",
    "            tf.assign(third_value, tf.add(third_value, second_item_val))\n",
    "    return tf.add(first_second_value, third_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data():\n",
    "    labels = [-1,1]\n",
    "    y = [np.random.choice(labels,1)[0] for _ in range(all_data_size)]\n",
    "    x_field = [i // 10 for i in range(input_x_size)]\n",
    "    x = np.random.randint(0, 2, size=(all_data_size,input_x_size))\n",
    "    return x, y, x_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6292387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24313396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7548937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.14759868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20687723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43344504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44294643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0692084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6156356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3449625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35414225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9894929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38299617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29296112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8500207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.12859681] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6100465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42682645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [5.6143465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.1981628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37222433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.495846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2275438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.5739472] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48070204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.692292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7569884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5612186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1817083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [4.3191953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63481194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.5503476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.2675285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7719933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38808382] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.13615811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6915073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.8998778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7809325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0189104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.17477259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29989678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8142596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41044328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3273995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22778875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3170558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4201437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50315297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2494501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8839785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41202104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23774537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9325879] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58059275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5125259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24975735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.1397699] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23670934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2233173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39300448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36377347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2661705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2087486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.552214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4091028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.4013953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.926665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.933981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.400974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56316715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15223408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8891175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7275973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.8832493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5967335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24997701] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.18545565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58139974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70895493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53518844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [4.1881404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8342408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.5912807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.143265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35970134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.16413198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31584835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3410994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6305764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3094885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42961296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.902731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15464614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.1200914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5540922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25777337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26027864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3660323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2283516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2392744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [5.251132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38237262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2719282] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.984015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9502848] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.8949697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2296312] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.385661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7764618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3851995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.18889496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7163321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8881026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.687791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72039944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1946489] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4664152] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51442224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8025636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2090792] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1999332] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.880979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4343581] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1612983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41185126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54587823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3408413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8102992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80171233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63858175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32210463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84016263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28251028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22822955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.17939903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6891374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1794086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58102113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4077807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7833512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99843526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6930604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7631768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76613474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.766511] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2594997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2967976] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74428403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28676713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6891803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15465792] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7866717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [4.2790956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4375116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41799474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9116388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6199102] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3168073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.5884242] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85131866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6471838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5635654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.21230541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.948089] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3410746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24190898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.14286765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.406963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.761148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1374476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5291322] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25568685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2161422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22734159] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2323538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29125184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30333152] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.19120046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44031706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6888667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8334873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8931278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59950656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.337938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9099053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.335086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6146513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.519868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4298551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44257295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.758295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6671973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23016843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96201956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7011837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2445949] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.17790118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25270063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5062985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2746313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5804964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1806307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7511704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.19973794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0803645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6153934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7275308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7031276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7769566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42308807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.203837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.329566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4244289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3074847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66084117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23606303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2408729] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15135546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8404495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5486145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3805147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91737086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46584108] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.754427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3893011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.5393314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6098007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.217102] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41901246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7281748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1454374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.516885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20653078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.342802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.18062809] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3140514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [4.011759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96186185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5725769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9466837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29201564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9040731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2626569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.04662] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2575498] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2599025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7545384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74967575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.6369812] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40515608] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52004176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37697896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5235965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.752429] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34600246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2797753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.8030345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7137277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1645517] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.13577452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.1161172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8386257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27512363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33767098] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.14989544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4067314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9249202] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24678251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4936136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51540613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90321195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80713284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5802774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98673075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4378069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41301316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3809992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6966602] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.16305041] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2901216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5765652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9942362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2526095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2087505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68492454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24253711] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9997631] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.16926606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22980738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5795748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7652104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0699706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8207147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7321026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.649594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58804375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89494604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5268931] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.149793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1065227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.16815802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1514024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.5064437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.026876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2641624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26865357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81515217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5004214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.6041875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0240796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27885866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2223403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.9877665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22562057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3718401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50836796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3184896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.1728368] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9812186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.061964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3902223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23752615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7088314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33223617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9338093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42767632] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0576131] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56859] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9309763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4460924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67861545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3054487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76983076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9612129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97661364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1699986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3782979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6136006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28643143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5705786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96184194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.21140623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27527583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0336171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29503137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8755523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.13323061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3874351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29617372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23828454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7285867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60294056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.18277171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5324961] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.070897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80493796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30669272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7154247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22334713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23785233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9160727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39516535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7678192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30556482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0346355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1927881] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8774109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0225555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.818155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6270206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70963115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3631373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1336415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70810395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5764216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27553642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5999491] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.9835603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6264772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40502614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6055295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0750866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45638144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23519225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.3500082] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7465863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2171576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31191176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3670992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64613074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53283805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0503871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44227308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7818315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4253019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45684624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24915972] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87887377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1383114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7274338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [4.274478] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.8726134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29843375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24242389] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7716151] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50831705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.17626841] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.392001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15785453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49985564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44745597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3950068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2111849] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0462335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1946471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3575759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25797945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47908336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78036994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2619133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7598411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0105147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59345764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7735353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7647377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23202823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3194695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.164668] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81048954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6431834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43038645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4903244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.18755251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.434718] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8070804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6292515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.9411821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5687001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8352163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.316002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9361278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0251262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20097402] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15892884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5030992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5362647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [4.84126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67387843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4112886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45167118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9488634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47358388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.5327027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62055826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24834661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54638076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3186553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.17853603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83183604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5436541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3405726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.1646012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7220063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2753052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36504227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5439725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.14425044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6800866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0285716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.13888772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.5137858] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3370974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57327825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0162708] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4684024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5675213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9305147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6522342] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1195964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0731107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28958917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.767921] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7487258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0282993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7395069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4670752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6046196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89393824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63755167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.306369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6911105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.1227992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48385224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8525078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.17242679] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.752274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7334548] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2850764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44980443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28621954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49215198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1311206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44116157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9117639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3353743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5226184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5293849] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6393723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3037908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80863327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.0557423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3545006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4486283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9036652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3854708] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5746118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6311498] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36317116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.908307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9060768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0832869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81194526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57051873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55517864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67017984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0724009] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.694456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6654354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69699967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9877984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9445769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36439058] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8798965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.338083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8069966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5460135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.460122] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85479945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4088418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2079574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8450147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6318986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.598036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2555145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43065056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38615078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7890932] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0092005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32433224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8830052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2106467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23142159] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8826829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59506387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2432742] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5087377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3022251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8408004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95386827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.77049] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.437276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60932463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7259257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3971615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33208245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2144759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.16575535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7014027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5087316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0600553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.8006895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92319] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3547755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3525378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3312076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.4580262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7720359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0782522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4824277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.0648627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7161157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8647504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2825418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0684869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0235987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.295956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6978247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20244807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64185727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.19394171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8277068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2160385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95769733] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3323426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56007135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28243807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4972079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2711401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.16266763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20620826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47009566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6335075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4727932] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8312765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7599268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0928246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3144054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98332983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.963109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6032665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37439603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3472089] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1439867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2518772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36500996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6991476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0819834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0782144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5549506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7612494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0937405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46581385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29061052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25750953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7925016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.734645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1164588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8119606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9837109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0270405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47972465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87487584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.83999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.879188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43080297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.496484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57625866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.107164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2203442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34668127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4924817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.19746414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30330342] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48091415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93981147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31128907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9164141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37222838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46462184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5114919] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95180255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44754702] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39119953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5422541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63499063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2818298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5806319] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70987785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0701725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1591903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8375458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.7935658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31914055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8767642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9436743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9768558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1565022] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35975268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.130911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3347014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0765431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27704197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80918556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2668526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31529254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6582001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2175043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [4.00811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47522074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76111037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26593432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5843983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5092015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4146153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70969445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.4315612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36238706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7548895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9554062] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8467048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6116957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4388735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6080233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2051686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8054801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37684846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29453892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5720814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2921371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3242486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59855735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4386288] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2284455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8386031] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6398616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1726407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6071584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31099725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0763938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6693619] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7648196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2014996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7264092] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7887452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8867552] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76068896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34225705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1341816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30381304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8958742] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3807419] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42130518] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5017674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6678842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7087494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1428258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6578385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.21737131] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7349398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89926916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.263668] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.258392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9980555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.736749] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2714256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26158246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49241972] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38890356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59690994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.639813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4488732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56457543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8660358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5820677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.186052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8830497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2957325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.4190986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.941532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31796563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39400348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.979575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5764289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45945358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3967445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1334065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.18790618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49887276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0687774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65065503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5828676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5054127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6403704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.19305655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4171017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29973018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9361738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8315983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8430284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0648203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5393636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67567444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.415032] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5121696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23141932] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8999059] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2329593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64663506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5985543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15443404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0638698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30963913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9694037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67375946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.1244721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4043692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0100236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.241755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2952201] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6205078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.369789] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37269217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3908446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0683355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48208874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5554537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7864633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34911197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39582467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7370875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.689067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6079726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39412695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72289914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84353477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30328596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5272626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7894927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8513055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65367246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3617191] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2561054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65639055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6147822] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6834807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6097699] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89478266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40070465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0212922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7119851] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3403948] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3703455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3982923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6005237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.837365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22436634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.377936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61934006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7006094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6918094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6015911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3254411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96692485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9760455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41351116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2651494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6666901] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82750756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7953466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.981234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1372337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9840711] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95660496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33840567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.934368] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89883685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32519948] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.376587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4378225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3763638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47223416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5355628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37874132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4126962] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2807153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64513564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3148228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48875076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6065787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.577193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4047681] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7957267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.320652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4549444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47256717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7061738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.491651] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2309295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4141793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0107607] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6962411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27366975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50485593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2726203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46429205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44802576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38985986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.422893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1425021] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.685474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.15670565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3941529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5796659] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3078988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25536963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74185467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85204947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25021687] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96636224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48198694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5670663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50497365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22252169] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2973732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25374234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.14875907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48406452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89005125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5810804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0859115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9337744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30603153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2972653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52258533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.369501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6452253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0637463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3037226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0370941] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3451469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.762715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.118187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6939494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.548694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5701933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5202205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9637989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6974925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9711142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55761313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30847338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47651297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33241695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6962653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4606147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4884045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5786123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4787408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4969677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5693574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1546855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7557354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2254497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3352889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83138365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4874752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2776208] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8784596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3335242] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6145586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4297311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1423726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1125501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4039188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7884105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41395804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3289225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3623567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75661063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2660095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2133192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3463966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25601974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4618226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63746524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.16628575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0630492] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20089835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0391254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5220478] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0162872] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77325076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2458547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4212209] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9371271] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37463987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4584787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26658446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1128478] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3688638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1529989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5368403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3139101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27614623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5055593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3784602] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56437945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9310857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1880097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7230321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2031196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41719186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30248192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25344086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.456957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2906698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1598933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23478022] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30141944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9233918] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79528105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.19858718] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43471524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2582042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9874219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85132736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.825732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6024059] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41837344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30249947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44498214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7622588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33245578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81889355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2844028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.768691] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.654649] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5720755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0007308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3560481] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5327558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.1672745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94580406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34712565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.73758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7949934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32165882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7592219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3665118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1898601] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76183766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6874045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7068138] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94748735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73774743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.4988003] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77425754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.331845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7337934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93230975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31511694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23610862] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9483667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4212486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8214096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0055578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35133547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69673306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8930914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39583224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5620936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24597915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.561587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75963163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53807336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0805488] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6222899] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43028396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43041867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1517081] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39016813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90530515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49078238] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22645289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3800894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4355479] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7068598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58709157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4122853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2577624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.497538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78808486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.560362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.000701] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6174465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1067195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84375346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.280227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0116975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5803369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0557888] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9817117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4437018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.21166348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4395784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5284187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8151126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.340359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42074674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5029552] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6636674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80946577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50581205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2686619] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33202663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86633676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8067732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3802066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49348086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5254688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.23270115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0964365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66139597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33609262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47890604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6662636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80911046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84670097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.6252034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.586821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36235753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1786491] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8169645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5064185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.880079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55934423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9842994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0719335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22595923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0265151] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72458637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.424549] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0267112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3676503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98682284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49759954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6141749] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27844667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.17906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2003713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44669843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9932525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7726748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5516987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2458026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85169196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60187966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8266731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36738992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9038021] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5257647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34604678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29053217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8677749] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3256226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7327836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64379054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.843585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87191015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.766607] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85707045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76736414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3041217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0273722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1557186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73351645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3751071] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.736813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22772424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7085942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.224626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59770435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64120543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8059248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2699951] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1499301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7902695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8514929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6606832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57289696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3313718] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1141536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1519345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32279232] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2249471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.119529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89714265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4559476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2030268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3668639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4533225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41727245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.165273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44480148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39928883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.25669166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5583998] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81228495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.915454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90380216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65752316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5782697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2254863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7791623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7890945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0809445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3984957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.510697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3030794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67671394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34037507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9492959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73243797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40380606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24940172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40299284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50948703] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7523538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6314611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9772998] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3484017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28392982] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8549379] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9233214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3173698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6718995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9403813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57076395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95337975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2796437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2030791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9396877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64269537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32198477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0254016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20608889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3808306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6530874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3584285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9464171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56761956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2079206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2389654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6167302] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67827076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4649386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5664861] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7662783] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0355444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4290314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26975715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6234314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27153438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39229715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6194668] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9504032] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4279221] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9505744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4081483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4068942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0627983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9252155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32390967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9909405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2495304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6316804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3439052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.512917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60509545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43603307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6929298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3440039] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43011928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0526868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8149545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3609059] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0795114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.18405922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1780534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7561574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38243255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5446743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.21132576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0624083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.513936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34341785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5237662] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72255236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85001945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7844323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53894836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79137737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54304147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5241538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5620431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.297903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24303654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1235387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6259053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6700344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4498565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6059376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73289114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2933343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3095816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24068688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32463163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74407405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8916464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5715654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2457445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7281811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6215793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7018158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6752941] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2345924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5674835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9745114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24587761] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0201404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9166763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95005476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39031577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35338318] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84050936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6454691] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2814798] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5072938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41416383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4959891] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9246174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3209782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92021817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7034259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7086458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2987591] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5638536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93150836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6698825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32245022] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4384322] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43522286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0867592] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5156888] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3897728] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72662985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92917496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58679163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8390091] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47963482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76271856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4075723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8024376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5652118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0754443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65534997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47315657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5486747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9119663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35012418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3746342] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8995554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35726637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9022011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.17761427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4022285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1186439] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42661572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3160382] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8611721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65964216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31265196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65085256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9193647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7972096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33984664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4716487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34404635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35211954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4300165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58565193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7309687] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38874936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93315357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6088904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2653042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8833692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8933151] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7291566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7026162] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4616141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9035641] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94079375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.281178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32561263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.768103] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8082469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9251695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48764607] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1212615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0298125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54544556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34756958] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.262653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4653753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0034819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46134898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99929875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60865414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5714853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9581954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45624667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8600283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5644999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5478814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3417264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80093557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5023756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7516373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.9820545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7950581] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47735083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.380381] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7593515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5763699] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26317054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8582752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20660472] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6443545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5868143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2564561] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1609603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82071644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0292192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4914897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3958076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5760404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8110101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.61586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2380321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7051263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71397454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7566927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2242584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33513886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0551759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9490418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82705915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78342843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5590888] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2176005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26616514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2130456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67811525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.858245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.2527514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5498955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73014104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0316796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3170905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9674294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.331745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2561609] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5682761] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3766087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [3.0285115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7913724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0262525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59650034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93413246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5899482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8295776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5850992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36633936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7641556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95033854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.29947442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77941763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78125936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6123463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6263752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2588532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7314031] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0336314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52430505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1515992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20947745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6540207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0483339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.20310861] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9138753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53177786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.605244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86450124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5870913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7381956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4544542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6651015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9410731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0621331] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3866793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1593875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79340637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5489974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77792853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1375619] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3361949] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80995107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64997864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4117199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63073254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8009746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5670885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3146036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2746889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7323626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78618354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8191822] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6738228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39586145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66700137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87988096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5084179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7383139] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39533997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1591082] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3114427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68621415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0999951] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9115002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8299384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.438477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2184901] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3789012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5048611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1157688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8343064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.548231] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8761964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8368592] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8816653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7379567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5088925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5803442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73211735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.183631] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1830268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7473229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7484137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79684997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78331256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5631851] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88876593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0197042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81352717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4093317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63360125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66664165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4569638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86875635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4429064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65058213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3119121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41866404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6139723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4550645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73207176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0255075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49844533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72116745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0139598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38803518] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84099424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61597955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1415884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5825404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42726666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4069189] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88012356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5885489] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1766766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5979837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7661672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2166407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46092552] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6570989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27708942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4157492] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5260298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8910866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9074405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86426514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0871409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1508492] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1485491] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.662881] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.827547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86576474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1712586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9369272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7728906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78468853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0842237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9569204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0411766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95485985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0841978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36004823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7965426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32428354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7938309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99253494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0200161] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1103302] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60100436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4510944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5954335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0759394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.27794826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31692743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5752704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78934044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6187185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8027346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7540309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0085748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39914417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8076557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9486043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68824786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51922655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5511713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.021786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37595385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56884193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3087064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9348923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8371818] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58514017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.309788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85871494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50635195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37567598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4349149] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84631] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67214346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94361573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75944364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84978473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96916795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6370017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8872721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.757904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85111386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52200705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.131141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6495882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3481802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94096494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5384977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2085292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26968253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34131795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56165165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79356617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.509815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82360536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4226773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60916406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63557935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85500675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50336534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5671846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5929183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6890441] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5595986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2103255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78302383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1039866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9304278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7614444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6741225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4850545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2841864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3813615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9189285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.104882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43666458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.581965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93229604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9046097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44624823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0131196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3677187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44986135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3344074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.466777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.6507275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5013893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8194204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.374588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65507686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5577267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45149043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80261123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5004718] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48935422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68738145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.834656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6744559] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79474086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1794678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6900125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.04865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5163888] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5219512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41332912] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5971452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99181366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2428234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6508205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6716326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0389835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89475274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7060666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1447562] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2944775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44215983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1137918] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67833376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68901086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9337831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6971737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9074686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0367777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8334391] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41966897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97873265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4208161] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94499034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5701262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51565087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5342147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6679956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2468971] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0962582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2502525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28972697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1976724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85856956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2826254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.509141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.901064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7547652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40615067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37703454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5944547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.479942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6463398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1706994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2392124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6107825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2562045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7436547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0238369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89605343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0331914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7909807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3281182] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45547408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44401416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87092274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69493425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.475636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0154734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8982008] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2963133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68120956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0659758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6241061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6310637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5277523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2563255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31056002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0392051] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45766568] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78130525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77531815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7526751] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4396467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0688618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.730034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52479774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2212033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36551073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7593841] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3934294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7546129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60231537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.22276235] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9107247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37422934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8531772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87206274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9666752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5406574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0964469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0963147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4661375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2273973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5423857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.507047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5453686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5592624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61575466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3101028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87983364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49518335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5935121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2798328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4069402] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2491395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49137124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6371357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88038605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38658124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50699925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.363784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8629215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56200314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1421785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39884913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7241474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7781373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69936854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8327416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4248041] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9849649] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.621613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44944912] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48764095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1855973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7911683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91404545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3513255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6065091] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6722071] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3264002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7472991] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1961321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95744026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90640724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74338406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.526053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0701735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6018567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88385296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9340171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87306017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99595815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8705573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8124898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5700294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8579676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8634361] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46649748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6694857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1011643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1320066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5469967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.34158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56337714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1922034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0814178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7216323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42910436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5748541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64752924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5690416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99405307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7446584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0197234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1456794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61410546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68725955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.864769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1170863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9514902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8914412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72464705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38338298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.673234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38100234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6701018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.506401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4608188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5287872] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8825523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1514837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28531727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9877832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.249927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7254102] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38450897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80729115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8287418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3306232] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9306665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61832786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1969041] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6441266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2977095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0209504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40491343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2506992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6583803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91871697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0420793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4964495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9257468] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38215935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1377718] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60986394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.248892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2827384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8388371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1532423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87798315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41572946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63262343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9871377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86574656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57429653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5631808] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2563264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9420891] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7202213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9818518] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7077482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38724476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58103955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4546957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3541665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0928619] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55068654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7434541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5370782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53920794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2203362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0092217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8491661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0019339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0742434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8866459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5802911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0372204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3882512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4711777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0079966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43511632] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9579402] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96210486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48647594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4159958] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47248375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1281983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.137389] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.633871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4465819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0316875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1344026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3572388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3177576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65919065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.24343204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94751453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34748262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5360172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1922042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.04792] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8890204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37910056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58301556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87238175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47877112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5405901] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4360272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3098099] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6720653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9944999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72618866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43629372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4194163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0457536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5284908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70504236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86022854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6004268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7089025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0394121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50931084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43841088] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35713375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1623354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3838246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9966482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35204363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37894046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99402046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82666296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37515855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4977804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0985644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85055345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8126752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2904024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6669131] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.506981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43801552] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58525944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73511994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46536908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7076315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4758602] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8516482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6390476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2896886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0105325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57600754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6266765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.26582363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9612676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48496678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7548937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3814303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4452563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4432707] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0917016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8926747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7345115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4452934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2245461] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93039775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.784687] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8233573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.685875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.036377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3159323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8046793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43157744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3905644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85711986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98800075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7028784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8235832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52208894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84318924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4819735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5399299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2264192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37636316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63682956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7050163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69511765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79477596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.679232] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5548473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53233004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9970101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4449852] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8027268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64115494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38598627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48446706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5507293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7826098] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64773995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45175093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0296172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2265989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88583577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6778902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81161934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1190106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.109647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89019936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44684085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87854445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.661574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7168834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0301371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53852075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3158772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4901877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5620363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83680767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5751915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5113208] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0749149] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3479468] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79447556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55183303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40678996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46161777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73549676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4600757] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0622321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6285522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0312744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33633435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6071143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66110164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5130388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6212436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79079574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74480295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7741291] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.305669] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64210665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51376724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9500325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4245428] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0367146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81177306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61784476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.373084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0086039] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.31413344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83399785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7350047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1435112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0884128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2334541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.875726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5676283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6089188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4051084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9993738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4142421] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5310686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8343617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96457595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.619971] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0853179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80264294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59174085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8715078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45839268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8402319] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71575385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4435441] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42245755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9087803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0118976] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8031166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75651217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81597567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7410514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1589653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83130014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7051569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1207507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9796034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95612884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80836624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4277578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83655244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40137383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6275887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.3262162] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65419036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87990654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.697917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1207983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9511281] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.401752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8039893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7034856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6454221] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5294001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.664458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9541276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44430864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39273688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88626766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9215555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1192116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97903705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45870647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1438979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6079246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1588969] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58120275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46481514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3723947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.612647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8225286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0348426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85687137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6755382] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2463017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9610279] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5044765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9433625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91575515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2478778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5528802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5563087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74557275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4512678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9563056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7273772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54546696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37245527] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53286815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5075702] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3087379] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64818263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82549727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0559258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37640572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7927706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5309916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0084236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6287565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9671699] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6434745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8054228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1437265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1470529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73318636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5891355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45082116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85717934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30308786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0583677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77486706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3494285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0232499] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6795799] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.888764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1560556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.0383513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7722769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0173085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71620786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81369233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92760384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3671507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36601207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1768922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.39248925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45269266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7755818] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88651115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3276083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96381956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.525267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0591367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97692955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83634204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38945198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86764544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0099233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5988616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5462768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6413709] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67851186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.485421] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7897001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1143306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5143169] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92431355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2835174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1732925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9879281] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.30322304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5506386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68486357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51057744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7592889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3354273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85014856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2563063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44493997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5503188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8842824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7982147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7947297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52854097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7170829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6383396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6301446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7149731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0642072] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38841403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.012224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6834435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4155272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0399518] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2601124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.756996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36655593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97143626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3542897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4498411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8643968] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95277774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.279944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96604455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.204665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6380831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78284925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58159626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0679983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2227228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9050599] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.36897266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.929166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4928769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94603676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5417797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44840026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8333087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7511373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5370054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2053602] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54786426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1230495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3499568] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42433006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73331046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80600774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3338716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50065446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2746239] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8461592] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2473681] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41456017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2049788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54279846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1734945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60868734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0668758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8277181] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89950293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7220935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9029077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66433257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74851394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1004859] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70676225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.232897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9342818] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70174736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65595955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55521137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86265564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52225393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4816258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85798496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4368725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.889729] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.2962591] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47253394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.964711] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5515276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40800735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3330114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71740174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49226388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70873326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81385267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7816672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3825816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3041517] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5015044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46968555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1905917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76065505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1575868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47712752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9047087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2918271] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96421313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84043604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90729517] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7781542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69223416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5417806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78700674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.086744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0917002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38347512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88615096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1929835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.486746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5745741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86787605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0181698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6292289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47121012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6380008] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2460464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86086947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60522056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81094265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58856046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62061226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9385123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48486304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.346677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6934645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63105214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44967854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7399151] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1542792] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7516307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [2.1576116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2536241] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63879037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52087855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7615825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6162971] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38372412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4994948] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.28719717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7784139] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6842468] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1361241] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1030141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7092606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9028123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5936573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.558715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6314434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84622276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2277863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.938501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4935169] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7977589] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7715124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98193127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46639735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9145117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2992163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81865126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8805838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.668517] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0529549] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37795198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.500833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6283635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4418218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7848864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4655583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6910664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87971044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99702877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9227621] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49668095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41236198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61926126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2525584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.9629595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.834708] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82238895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6907524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9293162] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65883845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4098253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5841653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48579615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9282886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78123355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46797088] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76087093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73810416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65491545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2421856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40757105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2406871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90591735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65172344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9492655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3306356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6447745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0676458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.33817193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5341884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69679934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63948697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76914656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70405525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8313035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1986196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67639124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8602717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0033603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46693593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85319495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8165978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.260122] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8116509] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.953374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1608869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75625515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6780512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5250339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60753405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1560503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6295453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0525628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41276753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7497442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80369806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4914547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82722586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49948686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80771196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75580883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55143994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66583836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44824263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96443033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1813358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.721527] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9618435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9287677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2006019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5230695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0948533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1163068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59339297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88277304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97381526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6992935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84039056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78549993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78114796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68996775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5004039] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5968436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76698685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2232634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9238335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7948606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7694994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6872722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6794187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77436006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88463956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87397194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8183688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2952517] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75238407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58772385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4429989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7066878] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1957406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67136884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1251667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61084676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7460436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52401257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6882821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0232836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6610187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64636695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91411775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57717884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8072829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6287332] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0819786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6379502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5375296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1722453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83005357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0263032] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0153263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60850155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7814807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1048582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5851819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3026289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43780303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2361978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5668717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8053855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4060359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83790886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93970454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0527998] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0281113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2386297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86356264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7690497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9931175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3434172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2631061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7508764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97977525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89154273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0281967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.793261] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8134433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55648065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89226055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4855505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76428413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86882573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.998664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9704854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6261033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59622765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6796373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9247801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4572495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63996184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91041297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73782444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80052847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73794365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9297884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48353404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72560126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4167063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7441162] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62670195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7351345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.946014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5018488] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.748067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.070048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86911076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70981747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63247275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0605769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76877713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5591679] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4701957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6169078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8537041] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6481044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8687578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7331349] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77703965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93220866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7505744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91826373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1814462] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8357769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59114176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.956756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69907236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99380887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7161218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0349615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.35699865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.38158742] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6232828] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7214516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.681279] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78072095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48750466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70870286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71854424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80530167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56142354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70956576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62714976] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71650004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1567012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9844831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8195748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1010044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8260594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73095745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.119536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6211801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9878168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0953443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.896219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.050129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5074239] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2421142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7559312] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80643547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6090988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1252673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9495997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57177407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1293576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0985202] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8403585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5445582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8495062] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48052695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6791606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.597895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4823721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85688996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0603515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59701437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66196376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7775328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.614537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9105745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0180341] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71439666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93728805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3333592] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.625244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53840125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61148256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85876626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1604748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6883225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8493272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9046075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2006274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.113819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1199323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55859107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1059244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70307237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6632353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7930722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68696976] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9761975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0864944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8615824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48172557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92195195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53157806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9704243] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7267223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5872411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57005626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6831501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0106043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0606012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0338061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.366934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9038841] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85497564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2689312] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1110275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85081816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77628833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52630085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49281478] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6792582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53937835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69343585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9438211] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0911317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64868027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9595065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8327215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9268384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9047495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9036232] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4179401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0212399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56406397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49949983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78525686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7736436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5032877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85234135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77773213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42416698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82456553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0308107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63138485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6623062] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56085336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0429429] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45480052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88270396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6031367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71199715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74652624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72495604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1074595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8379048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.754342] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6053071] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0396798] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5045224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6910166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9940693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8176927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6077593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.32776025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8080469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43873665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79263824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98348147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3604926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.663211] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.116208] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0083506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6146936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0183611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6850132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62246376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6543027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2341572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70454925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1483083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9268029] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60532403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7576644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0386868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2080834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0409777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56314033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6102176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89193344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46955007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5041396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1490146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84513444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5172415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0329869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54711634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7621928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61044097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8262973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7485935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7797111] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4506615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93628585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5908364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5198338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59686923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0640935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90528107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9370439] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47739962] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2114298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7105873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1253961] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.773567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9620639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7772173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8628909] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6525094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6150999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96382856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5632526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89091694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9937886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8105327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90482444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80852336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7229391] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7759967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84108675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86326844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5894714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3013498] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93087196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0060381] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60520744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2299387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7245273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0710174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9713933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7852992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5236484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65713733] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6686919] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5789192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80818677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.714046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87484246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98152345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7166991] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6933465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4780405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0443776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75203717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83094573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7468424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49062148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7854908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48114383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80842274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56153697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52330494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6338997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76268274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88964796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49497285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7978193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0882245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3882432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50811213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8396599] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8237538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41445133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8968144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6933943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0099996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7417657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37332344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85617507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5603571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42237604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76949525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9275146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8061501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2025388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9073481] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46003857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0321788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.677621] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1386503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.07168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7469689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0471184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8017112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46811733] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.576063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89870375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94619113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61292887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57496095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1067185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92160857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72384226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.960359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81043184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46252048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6511825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5686916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1618676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91406804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5944383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86445624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5682325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5770647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0303086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89862317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8832434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8731354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9346528] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9025437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65925837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90254354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1038686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0501063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7520882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45551163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8745477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88751477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55962265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1871173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52508885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9997122] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.026262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57891953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61592996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9478801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0306505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4538977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2181073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67985123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.34815326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8681934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5216948] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2440221] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0190561] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.054223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9506754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5052526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68904376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8232685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5788376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6085937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5868689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95931196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2944322] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.926329] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8450477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5555795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54670477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84441274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6364896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78577375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8247837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.282852] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71965015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9528169] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57844734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56035525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45787877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0143353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46147645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91150516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46106952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45009452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0383915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83057463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5909469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5508831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.990023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7837803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77794135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0273265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70030695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5785716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54964095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69443893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.723532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5874524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6635893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0770562] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86528116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64526343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1154928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0016127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7549492] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6971774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.3924008] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9703213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5914289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2472762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.143936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54625833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2615981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9335371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76007354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7289186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2981514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99577767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91594887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82179064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4188569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6445168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.909629] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0914397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7534895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5323869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54622245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7910353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7981906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63287187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7525195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6609188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92728984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2759364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6538073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0668051] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5075925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69123816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6939835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7849368] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67689216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7073897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64040804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61165607] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8986227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4849828] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75030273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7506363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56445986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5493567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6171448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8294867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69190174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49135303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9223642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0957439] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9275611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2384311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7244612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88401705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0717305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91185606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5992341] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8119569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71028054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4712343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0156348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5907328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4272434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5302445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5851375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8301218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1780844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5906967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88574296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1633112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78000563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59583247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.522744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57723963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67334276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2417039] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9023635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71283865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7912926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43239045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3254877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66766787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6518255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7138435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8491125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7214447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7427561] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5888207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6817109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6217787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8399355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1935084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83274263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7895144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6568612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0529256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9559268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.40293688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74546194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7405228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0003974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1076839] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1181711] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8097587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61674774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62537247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5104394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9017364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0361607] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58746237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77791977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0712085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64058965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0128144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7873533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5991028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8938508] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5277589] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79745597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8544766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51120865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5420053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9203946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.864116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8563135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80721694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80113995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6867902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.876771] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8065512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68751204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0132082] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9568522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8420061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85291624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.471147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8959647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5859164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6020596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.8036554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67756295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0210636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6564112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0258061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8407434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2015654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7909272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7082674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6966004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7094346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.387673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8437805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53999627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56638086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7691543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92261434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93371683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8781603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5342251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0088758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73849773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1331384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6888339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51501906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4828019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6427082] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8154688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0989807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82934725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69091195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0849935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8464366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3519514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0254612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83309156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1378095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5966733] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.178961] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8057434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54776937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9350583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73409015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63165224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4849894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6184358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5164173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0511097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6689824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75148773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9030423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45675826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76973367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2865056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8313007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6133403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9486796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6802453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7458458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0495884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1419154] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63977295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54935503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56420183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76642257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4073171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88477516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85415053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3285339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0760975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7570224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7405431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0997794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.6923351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8418419] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8050094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.808434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83425295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86595744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3069683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4557488] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9547765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4963671] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49747357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3248366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8285759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2504444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9516575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62238234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8671409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9315947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7913493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44422174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80577433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8934816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5908283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1458434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74690294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7196847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5280266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8353581] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98459476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58434564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.844456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0191289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0672487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92321515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.444207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2142977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6445497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61029816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9063289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47865295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73816884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1280144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5252102] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5752556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.964147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76429796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8081516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5341596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68985915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6939523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70310223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8136309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93200034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.535281] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93401146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72637653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2601315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8480942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0952758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75495166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43480027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8134692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45830193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55869585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93983483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97685236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1172471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83842576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9569384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6632944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8369991] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53828293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9731042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0454483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87734115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48959935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8777618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2424407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9677024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66815865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53073245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8176532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8169818] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1695974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0370263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6456094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.942291] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.066366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5057217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6542864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8382534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1402532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68424535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1122472] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.804428] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0364854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49041826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0441929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6218139] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.201515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6812513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9177626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88210356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87238145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8140945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9152689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7952583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7394141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9358233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6623222] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0589612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.868694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7367295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76961887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5768929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8302385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6622133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.570647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85367626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5047828] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8704056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43770957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5223217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8936308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64021945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48993582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0577922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76031566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63640976] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7293483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7542299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7732125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42236707] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.195323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63172257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5537909] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.079167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8755157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88665164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54522043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9050033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1278147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8312885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83465886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8943074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7959375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68478245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5938793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73503476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1512462] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9868289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43596408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9492041] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9162451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2413725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64334565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7454231] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.022392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69380844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5666903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3213176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0954384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7773172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70126903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7214935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5790094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6627643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94909537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51444703] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0967219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78487444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6914203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5414311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6982501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9844533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7420634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.7018654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0124645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73976684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6160703] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7650732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63547933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4878988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2827121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.37066638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87620145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73232967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0508724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0501301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.660192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8204206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65047026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6912943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6536631] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8710277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0215412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78204036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3605647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8448309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7939258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88338387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5822826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8462761] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9999655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8013726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93392926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7434751] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96129143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48288277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1411786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6142378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.240865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5084989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3745774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6803329] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8024809] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84427786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8909065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6255463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5477965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6512462] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1670337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4302349] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83723116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71967995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73375064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9271762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68632996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1829369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59700876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56888324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0218569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70729685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60305077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7541916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70779467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6772058] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0517483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5410307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0218235] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8391549] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72360027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8529519] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.44832203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6386287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0849313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47699493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3200418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79761726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.665036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7101502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7995772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8666371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0754181] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6827432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82951844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9430525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5134343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70972085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82541096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1023813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83449346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85466075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0587145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7204566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70750463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6171575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60139906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8794259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6683875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9378064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5196324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7782652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8004373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2922587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5704489] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89867723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6970023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5720185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.639061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48487052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.867659] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1078079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74081635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8762065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9066165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9157778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58981735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0372492] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99581003] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6420354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76955473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.051835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78798914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8071385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7486119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7329791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6583232] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51155394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.604435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78000325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2281581] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7995322] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8159449] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77253443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6264098] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6145382] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94264483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.880217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8097445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8239702] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2189432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8110747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55531657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4140744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6300011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0572923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68485105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0138385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76784724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8164869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5765555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65489864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0168698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7719738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61245704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86626446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7286854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78622663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63145745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0525769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67301387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6087012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.06024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.794438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78749144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9201023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62237275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7804047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0441731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.679941] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1038218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5654116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.136245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60762405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7643922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1534449] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82775307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86218625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0116395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95516497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0305253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88723385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72462696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8976956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0652723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0161809] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7377571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93079054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85495955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0071833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7211441] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.699178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70598054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9390895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61022705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74027586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8037171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9531942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8922558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63862765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6799957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74077135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82624304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60601974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57516575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67071384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9871647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8139112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8065996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71845764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8717009] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55017906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6921283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1609194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77800685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68812704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85021955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9054017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5927298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8606875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9325927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6463689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67551315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93023896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7446602] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6045229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5510695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7402558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84249544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63929474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8419157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7179415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74176735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90831316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8157341] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94854826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9103339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82492435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6354294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88019294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7241869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8417377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74366134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83710986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93538904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42982978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.41281667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66396683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6865705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7836505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76344967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5460219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7615401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7608686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78254086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60852057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7954366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6449199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7274618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9514579] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85522085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83511996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.083288] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78108054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72218955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87129235] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6971594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8481255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9579845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8916368] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0093081] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5587825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0520436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6815678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75233984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7164706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1739807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7691613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6540239] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.008419] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9302287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4168801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5845975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8599479] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55516714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67940676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6251317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5041572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8828511] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8686137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6678494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65427864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7520814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5978672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96804625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92266023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70892704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86584723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2281157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6787419] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6371237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61725193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80430824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0948466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71158326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9504612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81677365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9886837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9521009] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0874072] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.027808] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63662606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0841194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7274755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6603825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7204004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68514055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.009296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0836589] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86390465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52029455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9093298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6116867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9797751] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82282597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6299898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5982036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69967246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8943173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0369389] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92573303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4270811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75400513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8651527] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.246434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91376615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8260735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79426515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6020044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57862586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73875284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56901497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7288741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8385173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9966482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67547095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82128555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8704188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8716184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9058543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8433565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2142736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87501776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62744904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54793316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72522897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81433177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5287685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7856776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7185782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52103186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91285574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99346894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64796364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6800906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58836544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9276755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57011694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8222847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6983402] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68293864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73216605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7201516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.939904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72667307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7596118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65227664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9353558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60096675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6577636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8165664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8455776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6103483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42611566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7442911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4894308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7627804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0315919] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0721563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7508199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1063309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9560978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70590293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9119046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77388215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70065284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7106354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0450895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7521601] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0505986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9438613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6667924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86192197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9183132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0854045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92639256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60567933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6078665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89284825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5337577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50671595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0485939] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82083344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49707055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98006165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.654928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.779337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6192846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8450285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7690683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7395387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47015408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8932489] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58279765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5520601] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67716384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9980844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9596834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93145263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56226116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0227789] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73380184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0228107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7839855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8357415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6904732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83417755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62042785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6725044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9080898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5408797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8795885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0095625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7748261] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8495813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7759998] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66926897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90367836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84693956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8738151] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6694959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1205696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84798455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94286186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6445826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1676838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8333117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0062376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9132206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8301277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5833575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71979797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67710316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5924538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7255503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6967267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8064639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8966993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77669454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70511323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2590078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0018573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66733426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8017436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7613036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5690873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84626335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55081916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87740505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6041106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5669775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71544254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7096374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7651073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6788302] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7100988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0142655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2079873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59428513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8506633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82873875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48149365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8690983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7213527] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91961384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.797204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.42986047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7632983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67315143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57917017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8229603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9255328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7039464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0649616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8889654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52136683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97009397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7216397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0606307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95293665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71242243] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9818154] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7659695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4996092] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5517038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8413513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9713279] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6483031] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58854306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0246421] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9036731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71982336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9295188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.869357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51985985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68865573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6515378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0606072] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8286463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62006706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9394665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5805193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60366696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9315398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82295066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88736445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80112326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8619088] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9007759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71575606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82874566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9507716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8550329] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64430463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47474134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83815044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85283905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61249787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.056645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56168056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9246562] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.976274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5532359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72700495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9120474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98000544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5233889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.152121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69420403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43942553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8161454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65533686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0888784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93109256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0497148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9755968] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.590209] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.743279] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78972673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65299755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6558682] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68202055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.814646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1041452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8979743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90281487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64325875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6299414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7555319] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69765997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82073396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8086941] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1190101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73788106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9082134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6197945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6444079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5293852] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9449712] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5132791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86765766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53352034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50289947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0605769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8248476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7502574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5890494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91879237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7529399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7500262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8982463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7128185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62678623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61811686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76183504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7185784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6759875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6483642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8901978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84975904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65725946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0144528] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98568773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86389184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7422584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49316263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97662413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6572248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0060409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0152899] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61038566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1617182] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8440437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7001101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72946954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2123946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89167047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90522754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84924483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1973927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62538975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85876805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9742129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73471284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60159796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65378994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7480331] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7148259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59187555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7280307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7472646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96672225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1765969] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7255959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.993833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6028611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72400683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69983184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8248964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6278381] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71805274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68919456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66265446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8414832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50821745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.725335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8153831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7008437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5794127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6471183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8543864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71906024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52238196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87294704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0353074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.941553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0313865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68429947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77563924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0291741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91834646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7005875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77944076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73272574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3165536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9824027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6135094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5118483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55699515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59815955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8147076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9815106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6473157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80421376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0595318] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.767035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62712264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59278494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65809643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64366245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1134071] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82303107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7557878] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67455256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49688083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.172736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6746839] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7323973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7627025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8670825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7146906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7298684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.234444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7071239] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67935926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7874459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0637625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7438029] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78436625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6781778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89070904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9175519] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46992832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7036251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7428476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92881465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.106977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0365103] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77246094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6456203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64671135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57636625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84837687] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86183774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6199219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7614261] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1190641] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63751477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9826393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78499997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60901505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9017502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57230455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7701543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9368577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54880923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6251467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91877806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7945244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89168096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8207134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79305446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.665486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7477261] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78658086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6858969] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95068157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9463723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7784574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87534577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5005547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9265854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7162507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59728] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.5220459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68302524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0886447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6418981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9690182] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78001344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1018438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7911251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6982546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7281638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83343434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.228277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7831504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5998882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68614644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7110429] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9143861] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8348994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8348112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5865333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9517148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8076464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1054866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76004505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54789424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5618333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65686214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8039983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1285812] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81186044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7001995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.008052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79668105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2701226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0622171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.790375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0664703] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6317832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99388605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8480061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6161923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.907027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74296045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67137945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5609482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6640023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52603626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9109657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68533975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7158926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8242866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5118427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76139927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.142978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7332387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6089544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91978747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6951746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7233673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99050957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1529814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59584785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.522111] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64110744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7171244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4880614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.792199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.898066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3092192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1074584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8030181] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6707686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0644633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4968044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8863274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70488137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8558619] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83951145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.830709] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2617296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52161926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8457821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5639308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52539706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0969766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7848128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1990838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9325242] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68955946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7633667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90760314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76959395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48186654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7747238] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8375412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5906035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95272446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82014424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7400788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55866647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8513532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9133565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6320977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7968945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8894483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0089157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8795724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5543696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0417111] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62278867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6729089] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9898904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5947136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6788502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0668128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5774301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59302115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99298877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74253446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8189018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5424251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6809758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71919686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74627316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86714005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8591174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6417276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8823628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75363016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.170651] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7590995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0193343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7428999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4858592] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73970926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5284754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63396597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98013353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98273575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0290562] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78200656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8398556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68612635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86870736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5172264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9198106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95442593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86710095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57731867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84823155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1011395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99432576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75489163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58862215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8008441] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8530434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.993091] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9450749] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70589274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8539526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9272683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5584855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6189751] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8378661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0435212] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80735654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0253901] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7852973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9328608] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5420013] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94185495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6700577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2021813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7298044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84727395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.908198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8524961] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86656845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90834695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87108904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7338854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84698844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6423803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9678532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83767766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7589661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8254778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5993644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80964184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75314075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63264585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8610836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55158633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8537275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54616445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5510931] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86245066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69205874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54939085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9171957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78847957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7231372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7322286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7208035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76931137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45154017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1289374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71539754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60232437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.027799] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9398612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7582456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58931804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91421777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0427026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77204114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84047115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8744119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7989329] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67921513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62222904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71172446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1729487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9299302] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47491813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97863644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79140794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1086171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69019544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6844908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0321232] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7367073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6265709] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.164306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0006683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7294564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7544192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67803717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6929019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9673754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53711975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9757994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8414043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7301408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60472405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6704848] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9027903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7308163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.4636296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9050144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7924377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6677313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76613474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6422666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5570446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1571977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4355814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9384532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7501961] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99574184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0094025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6392532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6757472] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7789584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.658693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8852168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9140274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6996943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.279653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.868268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.812729] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84470034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66454417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81334037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8630415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7843835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9602944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78915215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9103683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5601904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9630902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6125066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1468297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3551985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3035898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67948866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7629287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76931226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86983895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7039985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63221943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66820043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1117297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1757092] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82616884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66648924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7474487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92525685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69237274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0615484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6112657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6159299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0679779] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6741225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68488663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75075203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6876227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6881153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9558117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62863624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92324287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8029625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7565682] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8068664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.528817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6325643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0981356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57417244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2014359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.849769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68133396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.673839] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86749303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8737223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0160432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6857926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81880814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8959551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53501576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6409448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82656956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.018044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8485085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8013347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9999672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69684714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72963613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68124926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60138726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75781506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68915117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88837534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5815868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8030333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7911388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1768681] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92581195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6114413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9505504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66839755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.579795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6301356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50722873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81811833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0655826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7496618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8251212] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87757766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78510344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6343137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0118906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94041216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6641169] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7128152] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0910263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83120865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7808415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7233668] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7095951] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6374943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.526272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6065571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78218704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2210524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73877066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82341397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7685899] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5919645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57458246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0562376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8764548] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7808187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8285482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1713327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8346493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54155076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3888628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5917258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9799999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6910546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9495767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8732316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84776545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61089313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63088953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0104698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8365788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.596404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8416428] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8270539] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7728516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6287956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0381143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6922742] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64761794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0084989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76963216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68222284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8648967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6330542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77374697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0118531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74283373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99474055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64041966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0817245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6390178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74499464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0265849] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.823034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8201865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9953363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9115201] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92771566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9021343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.702742] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8454392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9333561] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8951911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73260915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9081534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8333712] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98917544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6882317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.648287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79637617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9582048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6870683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7215364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76906025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91204447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8505564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6436502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7190101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78075856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76583874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70203686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65392816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6829375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0309156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8565034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8127535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70041746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83255404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5955715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67986923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0361753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7981271] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71886647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9094535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88518506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64806837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.919939] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8529179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8218664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61404836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7066509] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8609104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74517035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63601786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60965395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80874085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8285673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63476944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8342221] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70713925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7249753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8923539] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8490156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9714124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7819344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81655395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6613395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84778094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7338568] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.775642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7159477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9074744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87941134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47887766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.43306762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6880212] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66909766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8345438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75652105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5899286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7849178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77932984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77189255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64083296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8406774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6525243] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7302575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.845682] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7822168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8412971] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0636032] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7621741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72100085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7569542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7310721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77978134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8897923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89324176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98259854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59063274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9481035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6494659] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72218573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7753252] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.191747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68790877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7018598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93836075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85079396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2019064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61414814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86115927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5993448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67254937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6416765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5183215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8928627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78212434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70851976] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65252924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74012566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5956042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9921169] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6949645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82246274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1686304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7015214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70266896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6181917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78224766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0481651] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72465813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0002048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7614342] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0175059] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82874113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0668906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9788274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6813035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0624766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7458417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66434216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68157136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6858099] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0227572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0648378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8564852] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54071295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91144145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.661596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9807931] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8739233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65214986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61624396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71189696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83518934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.022392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8711443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46625596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6763904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8765147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2261175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81400156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81309086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8068623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6417986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.632383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77677745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58102554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75172627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7879392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9385387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6925165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75384915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8831835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8394506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9025303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8150725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1040769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80320674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6588916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58401597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6850053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8319186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54709363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.757756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6885036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5795136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9608426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96419513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66296864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6890806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6063199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.863929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64447826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79975176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75031394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6704917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72440964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72125894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85345566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6704167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7567415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67639506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6554042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6404348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7344675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8542627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6100506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49582392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70538485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5240395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7478708] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0484128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9325112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80584216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0896639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92470807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7532567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85644174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8217236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7470763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73413324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93753684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77443933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9924396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94674605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.695891] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92014104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8573236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0128889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86289555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62800133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61262345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8904118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5759684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5091164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0026026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7993339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4876147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95314586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7202326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78499657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6269376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85023665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.775241] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71073586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4818896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86129695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58149165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56252176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72874415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9618936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9829428] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9171146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6090758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9308595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74613374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9703081] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7869283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76697314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6463765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81563854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6103569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7056019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8783488] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5271117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8652574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0083859] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75353426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8160665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7583772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6366831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9701231] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8572164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88423157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.714122] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0297496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80652666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9101282] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66887426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1328242] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89834404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9710259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8822542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85867476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6161357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7612785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6793283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60341334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6869808] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6866217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7726632] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8513308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80771756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7147195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1365362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97739774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6295286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78749824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76955503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61798275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8762623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59267515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90594923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63284755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5933136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7698778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68569434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7031741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7979034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66740984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98028797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1122762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6457628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8515692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.836544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52715594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84857666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7264802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87515056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82487094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.46552765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7110166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7420311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68467814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8443822] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9196354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65696496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0001314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8741323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5624486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93465495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7472189] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0107569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8849384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7002024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9438123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74833673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5160223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5401197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.804622] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.973628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6743821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5983059] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9786176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.889152] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7142437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9013988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9001595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55776876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70590127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7038123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0074627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.786168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63323873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.982224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58313227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6196302] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8791882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77351904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88126636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7601038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8224487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89394164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75220704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78762215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86844546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76032424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59555733] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4878439] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82110256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83623445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6465393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9830257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.583359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8814432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9544326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53980154] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7891624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89682114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95390946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56598836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1099913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7024507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5015817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78309035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73832196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0066793] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.884748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0422128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9827759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6384024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76728505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76722217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70046586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68511784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7335701] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7528104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0074683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8857869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9267617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6983842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67652035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71376014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72808963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83207566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80065835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0337098] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75405025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8849404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6411973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69499135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5721724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9124058] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54370636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8444459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5740471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53701645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0701123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8174683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8437516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6136211] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87264764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7382529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72904193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8316741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7154239] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6554932] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65424097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7983126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.716021] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7324856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6434899] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7995893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82885486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6683158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95674014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97020507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92234504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76816434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5563909] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98053735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69369245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.888844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94519275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64582896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.106872] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79248285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67082334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7304204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1621245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8436788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8977468] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86775583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0774686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6161063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83883965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9109454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6433513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71636266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7207294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6760441] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56689143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7205893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7945988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98264503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1278464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7659708] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96030194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6611147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7416424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70907366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8393338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6063733] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7200186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7144538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.691898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80844927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5192672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7132551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84965163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78767914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58978075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65817684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8663403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7339005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54357445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8492278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0067306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94490534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93108666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66451925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7238724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9945925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9181237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75893044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7630967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7400897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2240721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95107263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62166965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56525135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57266897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6040069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7996832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88125753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6828403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76818925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0004532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7560427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6458333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6283137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7075559] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6285238] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0389345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78195983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77499926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61398506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53332114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0896854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67957693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7725079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7854947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8676853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.713009] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7243523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0584428] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7221475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70508057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7612031] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9903965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70265996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7841204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6878364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8053454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8912522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5130813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68239653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7432927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8914658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.099268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98287845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75128603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66078293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66525406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6122313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81780064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77802664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63719577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7582384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.136737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6271164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97005236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7857042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6164356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9023343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59848565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7524032] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9807267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56688124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6756011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91295433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7603954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9129272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81832266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7878259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6566249] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68543476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7713835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68797493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91361237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9411895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7421411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8850362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.518024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.941145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7922917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5985118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3716236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68099165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1173118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6370213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9353161] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74549866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.051304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79451394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68581486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74591625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90869915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1369835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7486352] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63322425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75463325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6810451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90421844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7814269] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81609994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61936724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9272327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8394544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.08292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8027634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56732243] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6104275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6623517] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7932627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1406505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79970914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7042079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9704537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77413446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2259399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0767527] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76669794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0218893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6559308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89967424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87424237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65939426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8823124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7497191] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68586206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6052074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6855446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53275037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83441305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6954096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6979215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7821614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5447398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7576193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0596516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67777795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60764897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89416987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69952995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7147463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9543392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1657435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57320917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5038301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6862984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68899804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5405353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74085236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9200179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2950544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1243464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8281471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6359081] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0428333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3870192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.912183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65520567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8774462] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8378327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8100407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2311906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56393677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7903468] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6021383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5411078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9792679] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7542378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1665788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9144037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.731698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70578104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8939064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75868106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50485986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7580354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8093738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5914197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8562093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8663546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74904436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57846355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8540819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8734731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6609655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7684205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82298213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97593755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8505578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62477744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9515161] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6108597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70784295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.033617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6727216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.645983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0373553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6079825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6036125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99853754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72820675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8257993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54864466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6778973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7273442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7696121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89381444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81798136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7070018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84867716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7689304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1196136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71619564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9841056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7293864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51915985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7036069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.568841] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6797726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99919546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98185366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9804617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7569107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7815582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7031068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8857526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50563955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8892745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9059831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8629085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6318994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83022547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0211918] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0169458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8088136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62444186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78621364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87132335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9048184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8940079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7403132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8084419] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8560544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5893109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.601542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8274043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9939953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87929964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97835314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7761743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87999386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57326776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8780587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69656724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1941022] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7594695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81178796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9195409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8385009] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89353037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8970471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91097844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7300547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79738134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6330842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9181633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.821831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77162313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84953433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61671436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7960137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80671036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67150843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86970615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57990617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8412721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61328816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5655073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84859574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7189467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58754337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84270126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80549765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7688433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7285729] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70128185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76720995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4697587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0892898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.762795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62713194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0030892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9734491] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6935616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6152017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92378736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9966037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74401665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84739023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85610175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7964288] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6748929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6356962] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7001422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.176803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8983746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50025886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99104613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73161465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0358081] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.719199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65206015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0413337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76275295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6603571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0838406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9428018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7015084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7810393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6554387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56812406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7120912] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9835644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5518066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9147344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8739166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7530664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6434728] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65191555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86236036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72088635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3383327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8547223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8175696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69252646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76493675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6428981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.597329] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0846057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47839922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97526705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75400513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9610646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98044986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6300929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7387504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6844446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8311003] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6568634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89202327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85641277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6544696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2299722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8787471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8254843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82932645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7164645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.796674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79731363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7706659] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97214115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81565714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8813127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61011934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8715626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6138132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1020027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2705611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2543845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68068284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7413972] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73018986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85573083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74666375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67716557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6759122] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0764896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0503674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8135401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63720334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74834424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92296124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69012755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9944777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6222304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6395993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.088822] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65802276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72863555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7477355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67400455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69310933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90490174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.677841] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8765831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7820634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7693705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7836476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6264507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1070575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6308759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.134454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8744503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6904148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65090317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91197884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8702571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98601615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68668866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8149739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8627008] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54294765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6059522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8243609] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97206384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8563693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.771299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96540546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68108124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74335885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7221765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6025251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70008004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6987767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8665429] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61265415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8201888] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78181934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.110311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.932212] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6329188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97817534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6533974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5814885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6272229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5197248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7909014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.04033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7527183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79450774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8529613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7211756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6608021] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0007358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9136918] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6723764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68255436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.10938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84964263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76162785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7063174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6975696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62352055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5384735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6058882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78019655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2115871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7075976] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8250555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7630718] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5715513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5496539] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.126518] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87284756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7668164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83123225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1419406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8421699] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53491354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3707868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57106245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9354693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6925552] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9124205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93755484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8593191] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63135356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61410433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0049267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8711878] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5879269] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82710713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8849117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7635442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.624235] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0301087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70143366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6669291] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98422194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75261426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63211924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8327432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6396546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7666108] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99380094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7813346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9336324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6788443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0513483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6601303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7354563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9603979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81967026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79594237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9887408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88479227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8747121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9108464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6906455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81525993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86714303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83271897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7298794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89714134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.819713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9759074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6720944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6237036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84601104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9643914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72988653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7073326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7498236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88141227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82826126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6444099] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7342286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8049951] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7288399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75547445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7008374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68646157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0548369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8787869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81701946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68572795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8065511] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6235123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6756464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97253174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8095298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73267436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9369333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87521905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67890567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94814414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80547863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8112694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5963462] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72667754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8225408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7522761] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6553951] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64784694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8434505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81668293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63111323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83297664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6986685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71641797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8813871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86456734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9864122] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7176608] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8098597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6754618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8342063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7356621] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7456807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70323473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9452385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84749824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50808257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4445924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7010394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65947443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85724056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75313115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6193402] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79321885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78611445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7662363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6605843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8630017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6547343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7293902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7885643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7402233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84349924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0467287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75409234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7214466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70055526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7433106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74401635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85368586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8956979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96580297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6083358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8903176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6347762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70474756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1966457] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64870995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7276825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89722997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8107087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0899662] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6333031] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85882735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62305564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6650274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65079904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52690184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8951897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74050575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73013675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65191513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7336184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5968424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0001298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8327931] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68114924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7963357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1344554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70920885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7421843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6166748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7728979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0165267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73114806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0225437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7266306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0360142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7645524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0515653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95176244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7044959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0448638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75781155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6686029] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65968263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6864871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0265987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0451559] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8470709] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5500834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9162121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6901924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9781817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8989598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6622624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6261591] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71923274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80333567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0136092] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8423146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4892504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6343719] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8848469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2104669] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7610401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8052589] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81467295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6604307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66299075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7997614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58441573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7647922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76213616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9028497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70234436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7185177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88577175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81963384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8975239] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8011652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0430994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76599926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6726817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60827667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65828276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8379281] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5583932] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.745015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6719836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61096025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9851144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9434124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6735491] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6928429] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6163559] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.827111] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68780506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7915219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7758814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6644333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7193797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7226125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80667746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63998914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75149775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68759394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84131354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6829314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63031065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6938541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8543242] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60795367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5384106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6812691] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5456692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7398821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0522258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86099124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.837994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0746448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9051372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7758156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.826262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84536463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7726813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74146765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8755463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78345335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95731914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9438794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70788115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9505773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82503945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97015464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82670224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6387369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61770487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8873853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6009823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.509944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9813248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7827476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48245713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9380206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7562043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78525573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63202333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8500505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77531093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6905782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48771194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8390546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5812172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56328815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7592768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9410449] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9919727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9026086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63218933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8839307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75171834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9425213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7865756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72812885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62221956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8033842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6076783] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7233795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86175895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51790047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85284585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0024121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7401168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7950562] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7481209] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0014588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86542153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89148706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7368116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98176885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78453016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8920127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6828231] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1127136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93492335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9510083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86507297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87553966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63262165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78634024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6789199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6104735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66745025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68009853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75455827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82557684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8222853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72058284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0668409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9629389] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6113614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7800365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7735435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64577043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8902348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6158555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9153567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65042675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6075353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8030183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67414886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67022157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86550725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6451061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96365225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0602012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67408884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84865373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8433831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5552597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83402956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72318685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8521367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.837301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48583725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6809307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78075737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74651647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85083693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91336095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6338028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9685626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8628522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.587461] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91378367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7606918] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97978765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84479195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6959533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9216822] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73850864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5231999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5335454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7809989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96855557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69141823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6039177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95164424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87791765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.708889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87931347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91499746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5805543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7126248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7341917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9787134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76365185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63905525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0052707] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58162445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.627988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85001445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74165255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87325186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73586494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7995628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8868071] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7740154] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.763915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8229206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7110967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5716641] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4951833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8117487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82734716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66691995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94075745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5947237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8559887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9447085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5316903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82144684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88983727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9392172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5896705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0835451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70622957] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5386608] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76217085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78497666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96169007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85875916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0347824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.982815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.663245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7763455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7518766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7283613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70160097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75952685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72488904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9565326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8798688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9348919] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7302326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70032835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69243526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7417039] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83323145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7955692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98793334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7653028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87218666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6508528] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7232378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59537643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8964609] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56001806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83146644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59453857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55701053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0734391] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8108645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89348054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62810946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84262013] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7304765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71356183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7952192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71403545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6710049] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67155826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8161704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7140163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7660355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6415984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7531414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.810739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6763883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9234653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9576645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95182467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7817351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59177893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9823979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7126237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82880896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9059633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6637422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0759593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7616978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6550362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7302642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1320006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8207091] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89230514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8792293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0112989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6108829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8309716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8751455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7260807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66662383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7499782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70324206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65666044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5509113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71855575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8186735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9875373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1027596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7872198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9443537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.693547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7500544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7167315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8427476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59600323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7182551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72666377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70720375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7888005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5230865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7069139] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8662509] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.838442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5908937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6606555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8712042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74097854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55666566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83692443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9923111] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9445227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87998366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65363264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69782925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9694488] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91540253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7902919] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7541292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74024135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1693693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9268395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6233651] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5956311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5807321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6055191] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78749806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8275341] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7031856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75145024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96578866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7470557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6555059] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6440589] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7354898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.619975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9952346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75942045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7823386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58026105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5517306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0434593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6819599] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79039913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7947772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8624941] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7121948] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7214843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9671706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73032534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7145916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.746914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94790685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68199456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7844833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6909411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7579155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87348354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53846174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67045397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7424948] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8705977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0903105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94855905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.738663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.667811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6787726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63011837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79931706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73523515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6456373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7584066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1410165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6161749] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96420544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78612417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62061054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8997352] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61294484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74037385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0024853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57419205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7039825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90655565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7425452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92446077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8109533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78370535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6520468] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6532682] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75996864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68971694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8908992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9380664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72044843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8880425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52727807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94734514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83275956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6004178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2898602] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6765373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1278226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6350942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91484815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7249735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0247209] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7974586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6749689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75493073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9517385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0836258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7279289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6503364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79043293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6645137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8948331] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.751501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8074837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63866585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9161912] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8522534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0662508] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8267501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5777984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6378194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6634396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78451717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1443839] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7907605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7047553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9511299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76304114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2013516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0813726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75240767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99407864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6708678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8490481] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88917285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6848066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8632689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7535684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6888423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62900746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6945934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5362264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.791412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70042115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68796146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75833094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56265384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75487113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0106578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64513654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60662425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8746292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6993375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71078074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9320488] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1756737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56011033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49139133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71056604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67192197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57143974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71088165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92977774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2854453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1325048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8409865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6171271] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0294745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3245105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9260396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6289252] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88576394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83359826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7973908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2113438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58898705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7607063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6219869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54914296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91585827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7333484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1461905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8995164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7565131] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67252284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88519627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75247544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51765704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7481015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7940314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5914079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8052803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8938461] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75211084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5902391] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85174465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8503272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6768554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7508613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78694355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9563032] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8311013] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6656219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.902658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6038287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7257842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.055422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72020847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62661505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0224715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62449795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6088389] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9953842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7182545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8294699] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5519821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6761637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72739834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78129447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9061444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79385155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74369293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82654333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7765184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0900652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69443846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96723837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7175274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5388825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68471026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5899068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70548546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0067964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97889847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9527668] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7453779] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7506739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71427464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89412224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49819344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87113863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87894344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8603078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6630372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8183891] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9750656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.033336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.840545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6447058] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77446795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8797889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85824114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86474824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75902635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7834405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8176467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60605586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5917127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81585366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96739256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9185275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95195144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7711678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.851567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59068984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83807504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70993954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1848344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7764286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79249513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9234877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8284454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90608597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8864452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9306803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7268618] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7685104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.628127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88963044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81268173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7781042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85852516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62811136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78645766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8368261] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6941386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.876281] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5953826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8322331] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65067714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57154363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84198445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73144275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61012673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8012821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8149825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7911762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7232691] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6892338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76552373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47967058] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0654738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7876732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6385367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9901356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9901334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6587411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62930715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.930938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9701907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.729477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85223424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84150684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7924188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6713276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64099026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69324714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1742306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88015974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51518756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99537224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7009464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9947673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7358054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6333753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.04794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77744967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6781857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0406744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9074677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68449724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7932427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6424967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5637739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72322243] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9950263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5601004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8821774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89161265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7657124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6653871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6391878] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84127456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71280503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2706434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8296866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8285669] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70307124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76246774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6408282] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6190672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.042049] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50387716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9959816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7522557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9390762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9604727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.625595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71936256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6854599] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8602271] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6528515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89434946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8242415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6283415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1988657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88255984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83311117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8225881] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74704736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7873942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76393735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7602329] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9765142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83049] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8640143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63993603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8222442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61491245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0796916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2229673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2217754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68136954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7286211] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7082851] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8458412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7684186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6989149] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67848533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0538892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9856112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8028654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6197884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7446811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9203448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68540865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95586634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62911665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.650173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0973119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64916927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7503923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7445617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66441375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6948879] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8763352] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7030516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8531768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7690877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7729337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7709692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59937173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6206299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1123673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66098887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.095486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.885099] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69456905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63583815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9395527] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8639417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9696828] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68615437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81299186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84003997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54429567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5868329] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8208669] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9461578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8601626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7534012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9443174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6702198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75057435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74686563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6030754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6703791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7022176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8562248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62662345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8305097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7739728] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0714805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9312126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64311886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9920581] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.644623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5805104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6258728] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52594346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7746619] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0244579] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7527033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77565634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83451694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6876829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67512983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99547327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.899671] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6741578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66515136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1171725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8560901] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7479617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6946181] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.690689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.613764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5467514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.603916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77692425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.20297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6905745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82442206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7578734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5587148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5336079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1679001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86924404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75912446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8321277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1235678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84310997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5308181] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3586048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55883384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90878695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6914959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8905035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97484326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86190534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64258695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6023104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.000194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88846326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58265674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8172772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9170479] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75653267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61935765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.024854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7047686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67553914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9722353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7408313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6063837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81358093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6428802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7604131] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9828683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8035592] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89833224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69690067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0337802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67298955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73021966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9242197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81650645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7808665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9856026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.867764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84592414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9153218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6829363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79677296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8318116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79859334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72757393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8911024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8104694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96638083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6631694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6106056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87190306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9650987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7524278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69662446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.738406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86008066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.815897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64287734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7383068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81869036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7056409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78311956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.726959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6861746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0675627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8897264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81933784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6743738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78902125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63931763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6739351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9383995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81542677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7377969] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9485525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87002474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6949597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9602908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77629507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8036614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5856668] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7384926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80024034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7592142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6662158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6709635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8599254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80744153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62753904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8332] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69180226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71138424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87350655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.870858] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9952477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68349266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80436015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6824348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82832074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7339168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73122644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6968808] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9643657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82864624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.523933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45021892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7073127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6533546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86608434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7506699] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6374461] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79454005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7875245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7625075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6714347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8733443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65420616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7269404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75607187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71525896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84389865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0335351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75022316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72151864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6706816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74568725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72386205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8331273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8972768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9551683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6171422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85719436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6272358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69408685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8182519] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1966928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6283737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7408219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8723804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7888136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0293686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64452314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8553871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6347371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65848607] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65512466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53155684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8941313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7189847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74078697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6509139] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72925997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5979475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0010387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8117734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6697407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78025264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1142129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7101577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76453424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6139838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76831347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99538445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.733609] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.031513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.704375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0472035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7293715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.040297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9359486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71541184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0314372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76473176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6712969] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6465265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6863791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0260538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0288758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8384157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5533296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9197481] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70555156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9742982] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91012657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66584176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63064283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72276026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7849759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0081303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8260875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5016715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6103796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88970375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1989838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7314309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79972583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8188798] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6679141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67915463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8129671] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5839071] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7712842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74794036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88058865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70724434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.698539] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8846334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80660194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8922746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7937228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0083145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7455068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6775717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62336314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6403322] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83865654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56438005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73816484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66192037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6265175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99650496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.929044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67993784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69364935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62106067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80472946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7115731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7883087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78725207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66068137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71535873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7228558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77995366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62228024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7461369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69195163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8202676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69558614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62354696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6722337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8510954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6049666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5621892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6658318] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5582229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7349817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0511913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82214576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8557786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.063041] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89228624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78571045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8089277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8560219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7859903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7417191] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83892435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7859532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9355338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9391061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7115885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96557426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8069349] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9445929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80527395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6432128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6210883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88454115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6145832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50930834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9710337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77056146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47890833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9284326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77465755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63470805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8479253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7730185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6764883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48973393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82374203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58038294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56041145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7762034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92814493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9947521] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89046234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6424105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85870844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7533997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9269772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7848095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7051201] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6078422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79486215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60685503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7322] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8518962] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5111896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84313446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9959422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73116994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7812643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7415368] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.602868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0148144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8703034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89556575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7472886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.954917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7718897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8810938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6901537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1005442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95454735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.938856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8548263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8847124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64005744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8003475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6774472] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6141884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6564207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6753109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74381554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8098907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8281689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7232925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.026116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9538892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6016832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77555656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77481246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6604084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8961322] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6277952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9165638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6601787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.614259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8218002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66785896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65130347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9014427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6324303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95449257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0308713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6886393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84463835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84805137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5712437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82370406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7176734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.839294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8419497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49638313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6629737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8013558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78026736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8509002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.907829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62140936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9524436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85434645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6016191] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90072274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7668823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9604955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82024044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69414073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9083665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7320979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5251785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52893376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7654837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9620294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7015159] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6063801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9349294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86929786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70408726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86287946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92123353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5931579] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7142217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75071156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9623797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75067306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64076877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0169272] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.578601] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6314944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83267534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7209576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8659977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7208252] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78522044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8806679] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7861234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7495916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79678524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6837263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.558849] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49839646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8055328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8217478] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6783204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9158214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5997788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84037673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.939973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5260293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.837268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88598496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9299734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.601726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0668856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7070837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5589424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7486312] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80966604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93593776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84313136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0283542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98035294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67497885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7785454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7411174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7436658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70994544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77180094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7113383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9285038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8762336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93614095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7114722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68039054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7467773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83049273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79153675] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9623608] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77188975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8645404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6541622] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7380731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60691625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88797367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5678412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8235691] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60388684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5676792] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0738689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8054251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9184757] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63583434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82274896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72560227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7020293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77401763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7112286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67844677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67891943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82374555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7119094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.784894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6401112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7278842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79682463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68138367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90381706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94818646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9659034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7879712] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6102171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9826815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7217182] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7962309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88321525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67189384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0577734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7424884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6455271] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7289875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1134045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8089691] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8879952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8856624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9737581] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6071884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82751876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8538338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7246864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6786414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76708615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6916855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6460717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5401157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71770763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82993555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9875625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0889301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7976506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93621254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7103342] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7531782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7216573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8418683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5900847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71510273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7319647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7142918] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7765339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5230417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70302033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8732714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8666425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5881371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65950644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87230873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7435038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56395495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8297466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98421025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9428542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8524906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64672524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.683846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95187104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9119116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8063154] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7484894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73738813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1367595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9093168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62231517] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61158276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5840323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6046361] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7781285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7972175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71381176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74296266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94467485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7397722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65952945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6496024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7501799] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6144987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9690475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7461791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7840911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56019014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5598896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0169357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68229693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7971206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79745024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85617256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71101284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7193746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9175079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73421633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7166448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7381934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9225748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67044306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7842753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69066846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7300654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8613114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5523716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6628611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74087936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8579237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0821639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9266152] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7304875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6702735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6875027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6381535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7875155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7119725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6490612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75862396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1399577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6067179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9607198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78553164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6221529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8960003] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6203061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7317958] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0124351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5759754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71898735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9007042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73232555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9298153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80302566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78000176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64876795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6353964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75130033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6902598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8764146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93561655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7067871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88771117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5314203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94925576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8529463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60142434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2443147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6717082] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1303473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6337438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90190667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7120952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.010017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79902357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6663554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7587087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97539145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0515069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.714739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6582376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8079679] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65458643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.886896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73399794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8027937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64929754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91056174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8560889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0543118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8393287] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58273065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65218115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6623365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77764267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1442456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7838869] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70331824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94036585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7567681] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1870066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0817604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.742968] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9764446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6792158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8202468] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8969165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6988952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84931105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75500023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68711954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6408994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6974769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53717846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7663743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.702067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6816697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7439457] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57150584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7521334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98113877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6250012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6051683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86042094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.697353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70810187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9179977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1821529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55155706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48262674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72249216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66084796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5883583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6924234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9330741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2789594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1356397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8469179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6060816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0209637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2881387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9326704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6139665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88760257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8287431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7891904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1984398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60279953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74390507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63138664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5526185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8802167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7189715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1331954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8878318] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7702645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6524421] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8789924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7482153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5239845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74144673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7847572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59037924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7768455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.909408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7521988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5965843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8478271] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.836259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68463576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7395197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76622415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9438169] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8177551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68792695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87513316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73407847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0656688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7473312] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61436397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0142366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63257945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6105657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9897689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71088827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8308587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55292577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6744143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72412366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78645337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91107637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7790016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76306885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8117051] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77952456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0724435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68265796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9585967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70792854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54951394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67389834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59987223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71888113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0085782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9754856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9362998] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73958635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7331909] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7208278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8975705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49267566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8598658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86300313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8578119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6796462] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8099842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9477476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0440456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8584142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6551696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7652712] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.882958] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8322897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8472705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76859623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7686732] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79576284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61439097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5852577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80589473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.952166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9388038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9363892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7677765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8353332] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59952223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81257117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7158464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1767057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78542113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7810423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92377806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82090205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91096556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87773055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9396446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72385305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7509204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62480456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8722873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8065683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7808572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8608091] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6346371] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7793648] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85316426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70637494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88035697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60282207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.825556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67006975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5730504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8382658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7362143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62256145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7770769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81966573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80120826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7180614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6812967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7637238] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4841208] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.050823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79976207] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64285475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9824401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9978016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6387425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6362929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93533784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95408577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72091997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8546722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.830408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7883351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6681756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64207727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6882388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.169808] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86903924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5230914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9959451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68401515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97087103] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7444502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6216407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0518098] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7850114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.686901] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.01636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88550293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6735158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7979781] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63418317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55981064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72897774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0020118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5639866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8637364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9005758] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.772021] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6768427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63010484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82939464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7063029] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2328475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81624043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83252096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70649946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7594768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6377251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62994796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0165906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5178005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0070176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.748661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92473406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94666666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6227943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70676076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6832166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8755906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6484649] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8941211] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8054216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6123926] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1789249] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8830238] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8371213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81878495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76408315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7814625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74590683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75232935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97712684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8383229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8531276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6566542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79441553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6149723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0677859] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1954129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6810661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.720263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6950186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83851206] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77874035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70833707] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67834145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0391223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95053184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7945427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60849804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7398817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91755956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6803638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93265015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63259953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6538519] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0999551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.643442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76035225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74122465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65729403] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.694817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85937434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.714833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84058946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7603814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77252144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76324975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.610936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6153114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1149768] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6758289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0720181] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8888007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6956223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62547797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95581585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85755587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9599166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6846857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81116354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82462347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54270864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5754748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8169949] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93094486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86136436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74201775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.930842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6624106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7534858] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76099324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.602677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65380484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70240045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85061777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63188756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83586204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76760584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0483588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9279406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6471068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99839187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6387887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5784218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6246092] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52831554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76409715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0138934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75111854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76354915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8211918] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6688821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6819482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.992465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89135355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6730842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65426266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1197027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85708326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73820347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6863053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68612397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.606596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55150545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6013867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7734537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1958845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68051875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8229547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75342846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5500744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52281445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1913842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.865661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75413173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83165795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1117531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8415556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52752465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.350412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5508297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8920952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6891941] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87711847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9956107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86067927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64805895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5937887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9960536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8961532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57875973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8099192] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9339501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7509263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6147264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0208286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7049346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67853826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9656881] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7324254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59207416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8016865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6436987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75525343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81558526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8772143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.704458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0230857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6800418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7267536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90340936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81331825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7707358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98350495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8563535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8293277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9169824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6773011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78473586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8117558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7788693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.725139] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88712764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8037857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9593648] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65736955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6027397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8847123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9636331] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76359534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6884295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7309815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84546083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80853766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64020497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.737568] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82574564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6905573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7964647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7406199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6843064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0740126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89447767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8201052] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66567886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7768512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64739263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6726547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9190773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81790066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7386277] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9526558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.866894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70256937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9645305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75765836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7977451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5784997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7447937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7865014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7640463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67153853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68403935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86696815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8003483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62396663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83317375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68613833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7078143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.867506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8724568] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9998333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66418254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79973304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6851846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8253504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73074883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72350097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69307446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9733374] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8169042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5316053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45217508] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7096135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64881575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8684114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74825716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6476986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7928528] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7865286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75944465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67652833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87754524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6523198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72382635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7365501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6997629] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84336656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0235227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7478106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7207676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6536549] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7439358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71155936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82047397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8976955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.948148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62072825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8374501] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6225727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68707705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82365644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1950934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6169014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.746916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8567736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77572525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9951943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65036035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8517794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6397393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6530407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6564829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53353715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8916843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70684963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7453232] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64927405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72572726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5980409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99900556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79815745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6607818] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7699046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1016988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7082988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77639043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61079276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7653575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9811405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7337057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0342155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6897332] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0535164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70903814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0319871] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92603004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71968055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0213553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7681235] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67228955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63800704] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68541265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0236564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0163596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8311546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55332935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92133605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7131362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9701895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9141536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66601455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6318279] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7237111] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77355134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0044321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8161795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50766677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5958113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89180166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1905642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71395797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79528487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8205981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6697956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6868621] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8200365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58171594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77369285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73936164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86632437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7089423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6862898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88229835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79743814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88736534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7891857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9877659] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7333772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67815804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63202643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6279711] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83713496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5668002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7335799] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.655048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6333777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0011132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9190178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68315303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6928338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6224965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79032713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7238332] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.786557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.791398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.657689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71166337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7219905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7637348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61110955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74131423] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69276404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80682945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70048785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6184275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65972024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84692764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60163355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5744365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.655498] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5648553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.731398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0485847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7997835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8649689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0544581] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88332915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7893418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7982874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85998124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7923399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73915577] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8166142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78536135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.921523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93402874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7114516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9722396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79601634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.928865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7919706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64434856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62257785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8819719] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6211902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50765055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96549815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7616656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47590193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9216212] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78325343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7804655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63556653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84520257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7699274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66647375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48951018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81299603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5787923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5564781] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7848522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91946834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99480087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88088703] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64597917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8443507] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7529096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9175706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7824442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6907069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5984861] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78853226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6059905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7359431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84552866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50591075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.835691] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9901701] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7248443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7717124] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7368123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5936306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0194227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8723622] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89724076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75127923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93890303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76387537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8738451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6933942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0926955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9644019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9308523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.848076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.889058] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6426156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8074324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6755427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61550635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6493248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67137516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73667467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7995719] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82962817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7238258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0015705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9477545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5957566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7723458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77441883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6673339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89795053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6332542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91453785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66484064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6166269] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83160067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66377574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6394921] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9195531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62447333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94859505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0136408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6953578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8405503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.850569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5795475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8161502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7121524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83138597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8427504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5011058] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6516903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81157964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.797662] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8484731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9031565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61404264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94361436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84783304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.608965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.891905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7689222] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80459905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6927806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8998798] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7272653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5243939] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52509654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75492007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95595145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7068177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60673827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92388415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8625785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69978744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85077715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9229633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.599398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7133867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7589419] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9524595] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74238545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6402502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0221753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.575142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6320887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82156855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7072096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86002713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71090925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77547693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8756088] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79214996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7403939] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7810788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6674307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5511751] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49898452] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8007055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81759197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68408996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90058815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6012063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8302692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9371626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8443241] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8832451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9234518] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60706896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0561522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7061481] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5690769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73948306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8219118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9203702] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8330209] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0230187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97720647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67971814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7777421] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7332952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75134826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7134069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7769644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7039912] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91228414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87334263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9345489] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7563493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71589464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6727437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7476657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82651126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7879306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9473227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7749587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.859358] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.654209] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7452042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6119019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88281035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5707778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8182074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6073365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57260686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0729736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80095506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9302586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6392766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80923295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72194314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6932129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76089233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70802367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6812172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6812004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82589746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7095508] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7948134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6383067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7132087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7864642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6838722] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89176357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9411439] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9720036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7900418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61906546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9818521] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72540134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77740943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8694142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67481714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.046432] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7298739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6391028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7269309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1014882] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80227137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8842891] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8886853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9517184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6039914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8254741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8404269] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7231289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68409747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77517515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6836607] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6395945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5323635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71670514] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83436346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98557377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0805902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80212784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93151486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7182033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75337887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7241111] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8394984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.585933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71156347] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7336421] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7167457] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7683585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52108485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70010346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8752803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88152933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5839958] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6569299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87146854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7434744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56739146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82489663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97896093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94072247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83676815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6416685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67565286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93962085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90829146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81391054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74436134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73351705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.116921] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89683676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62012357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61911356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5845081] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6025181] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77092963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7791464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71859276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7380042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9312353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73380816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6602874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6501632] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7571128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61050296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9528801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7377564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7833121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.54743344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56253695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0011419] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6812101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7984532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7969946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8502862] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7092735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71733665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8891748] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7354925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7321625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90693814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6631024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78337413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68876576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.712754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8526987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.559343] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6574156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73876405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8494822] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0753068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91234064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7246312] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6702528] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.692477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64097434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77951896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6984143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6496636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7580533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1370592] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59899855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9579316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78403294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62189054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8920413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6234588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7253266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0162839] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57503057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7262522] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8955821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7257601] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9314292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7764692] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6457946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62458915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74454373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68971664] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8667365] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93330073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6976456] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8857937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5325475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9489743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86218506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6013222] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2182066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66718453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1295302] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6322385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8932728] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7034894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0013189] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7992449] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65961576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7594567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98779774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0314739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7057679] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66107714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81579024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6479836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88033223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72316384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.799498] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65459406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9070346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85589457] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0457149] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84522223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5843625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65896946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6601583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77219146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1423541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7783984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70084614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9336518] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.752513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1780925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0804133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7361625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9649129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6832263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8028308] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9003348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70611584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8391794] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75474405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6837112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64613265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69737947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53642786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75114554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70167863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6770824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7346068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57515705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7492246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9627362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61189884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60325354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8501182] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6947437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7056043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90881157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1857821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5453283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47614363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7275147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6531637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59683955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6803913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9330383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2743924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1359606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8490396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59890807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0152489] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2663765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9351074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60468715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88637894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82401496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7834885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.189809] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60970014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7336838] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63506126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5534553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85930735] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7088156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.124596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87869996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7772292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6396951] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87411964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74472725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5264054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7364533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77844274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5885814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7599851] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9176683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75079715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59942865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8436655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8271917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68760777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7317417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75353557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93526006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8082912] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69934964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85893244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.595567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7370911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0698925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7619157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60599303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0090405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6357847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6101911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9840088] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70508826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83076113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5522119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6723547] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71975446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78803575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9122503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.769309] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.772541] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80143803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77993226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0614632] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67566484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9535931] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7003178] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55447227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66697824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60378504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7251109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0075474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.972098] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92599064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7361095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72252774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7240875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89828354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48814142] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.852458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8529892] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85505867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68776363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8035792] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9310229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.050399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8679204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65981346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7580388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.883284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81696063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83625317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7729148] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75920266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78249943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61786264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58038276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7978896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9427293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9485393] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92662746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76498574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8253842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6032814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79586565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71762896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1700854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78959745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7735545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92229253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81495285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.911886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87080973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94301885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72087497] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7396233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6220195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8610612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8018961] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78143024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8602127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6377069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7738194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8615906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71227443] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88236296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6055157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8204218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6792849] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5722274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8356028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73700434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62875396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76215416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8213964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80495566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.713411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67566884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7616811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4852606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0414375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80487573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64353925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97716314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0006851] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6264477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6391096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9374688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94358325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7151015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8552186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82200414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78457755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6652351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6410915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6840363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1651946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8617356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5265687] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99479604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6738369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95639753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74820954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61358094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0534757] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78826225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6905473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0018954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87139285] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.665895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79892164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62818915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5561795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7313346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0055788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5650745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8525276] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9045067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77453476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6821137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6232922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8219598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70096874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2108943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8082762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8329901] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7064867] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7563756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63433164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6347213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0009333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52461827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0123696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74467325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91497314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93689764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62051487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6981372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6797531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8830168] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.644304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8925002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7938024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6020404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1657674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8818263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83877504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8158138] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77292407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77706164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7353908] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74620163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97588915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84196484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84579647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66531605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7779422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61401665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0607376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1788094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1862373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6799255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7142354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6862553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8327628] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7829533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7114898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6768172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0291777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93058586] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7881103] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6005011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.735172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9147211] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.675657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91800314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63365054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6540273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0998698] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6390996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76415503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7378194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6517104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6936463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84867096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7194556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83318543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7540623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7704884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75791395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6156482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61053956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1157174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68236417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0572927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88909686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69483376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6179786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96482843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85188293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95340115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68263036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8090477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8139153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53992516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5680392] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81311893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92152405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86096483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7342396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9217378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6565086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7537849] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7685179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.601451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64370656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7009299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84687006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6328902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8379439] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76238436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0341614] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92427886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6477561] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0006157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6344021] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5759085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62305725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52839166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75661314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.006399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74878013] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7553376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81153107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65750253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6843601] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9901907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8856531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6708332] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6468166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1196208] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8557104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7310658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68011665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68260074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6010386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55361545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59865737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7701316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1901829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6739831] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82119715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74968255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5438229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5151515] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2041723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8621427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7503264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83025247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1038145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8391564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5244328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3446928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5450397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8811295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68636787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86851895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0066067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8579617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65006113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5873647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.992314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8986502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5754729] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8040274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94209975] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7462288] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6104804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0174053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70345116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.678651] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96150714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72615486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58336174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79385495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6429399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75090843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97015446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82142955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86403424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7067588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0161225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.683294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72395086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8907069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8101202] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7633939] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9815862] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84824526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8190569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9168286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67272776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77638435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7995777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76675355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7225116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8839773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7986319] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9539428] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6529459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59734744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8904383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9613723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7685098] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68197554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7256187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83531034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8036744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6370328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73493093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82877135] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6802814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8021616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74708295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68183243] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0769094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8958727] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8197556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6589149] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76806444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6507952] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6711531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90742254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81828463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73740405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9532874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8645627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70548254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96497923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74522054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7928898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5731736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74757785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77743566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76667035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67350686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6908077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8691937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7947857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6204531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83247185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68138015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7048337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86265576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8717351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0016857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6524942] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79574776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6854855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.823326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7271299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7186905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69019204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97689354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80907077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5345121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45196363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7096222] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64501864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8677475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7456706] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6528477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78998667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7844893] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75656533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6780997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8785992] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6497877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.720457] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72409] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68960816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84228504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0159001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7457726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7192753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6431354] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74064213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7033746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8120187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89713776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9431814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62136936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8250805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6190305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.682061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8249633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1930327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60973907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7491424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84648114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76709455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97503686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6527813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8483247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64113873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6484502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6560657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53375125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88872874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6992373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7464905] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64712864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7225086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5971661] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9958765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78891855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65375304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7628186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0935118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7053835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7820629] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60744554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76285017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97129184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73246646] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0340524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6797182] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.056685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6965725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0257391] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.919273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.720454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0136971] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76920927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6719484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6320152] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6837601] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0205785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0068885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8251907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5516684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92128146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7162769] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96625966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.914578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6644715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6311321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7230477] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0016451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8095251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.50989676] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58630395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8919982] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1842263] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70299965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79142004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8206935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.668946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68977666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82333606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57884425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7736909] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7335826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8568262] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7086401] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67811126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8796801] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7905627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88295215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78594583] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97509736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7255521] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67673033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63645345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6191445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8347373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5669891] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72987396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6498305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6356259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0022023] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9117965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68419385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6911502] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62203634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78046787] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7295114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.785007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7919766] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6549127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70806575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72033453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75319177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6034297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7370948] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6917589] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7977203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.701459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61416996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65174127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8427459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59823775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58000755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6481874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5677759] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72834486] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0456188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7860859] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86914194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0480723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87668765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7898959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79121834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8605585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79481965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73564196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80249274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78335226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9120897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9292355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7095946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9744635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78882825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9187653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7832133] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64370346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6225478] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8796012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62369984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5053744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9619359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75504386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47305065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9163209] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78646415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77749044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6351669] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84236366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7666554] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65913177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48803246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8051612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5766289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55247086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78863] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91311306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9936445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8734106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.646201] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8355909] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.751251] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.911284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7798313] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6810747] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.591823] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7834977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60460097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73685145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8410073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5014936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8298947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9852362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7200887] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76470375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.733049] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58686656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0199147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8724413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89729744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7519147] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9286499] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7582186] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86854494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69416356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0872288] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9687114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.925094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84310716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8904711] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6425812] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8103663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6734533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6152578] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64412844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66788137] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7313872] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79222697] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8288864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72299856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9862096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.943202] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5915197] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7696544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7730417] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66987836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8976857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63505167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91140103] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61656624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8360182] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66060495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.631431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9279746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6189091] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9441669] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.002967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6977171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83671397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85137254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5832118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8103604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70723265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8259349] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84169275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5024701] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64411086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81598383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80590683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84522897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8991752] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6090773] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93825454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8426937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6121974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8854529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7686885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.940005] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79413724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69126284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89403445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7232269] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52222085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5215862] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74737126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95073014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7089997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60578716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9160648] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8571866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69587797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8417373] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9223825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6018284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71142346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7623639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9459065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7364837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63854414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0238738] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5716568] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6310115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81385154] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6977411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8551827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7038982] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7683269] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87139386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79449505] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7340361] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7710845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6569873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5459635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4980183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7965851] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8141119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6864265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89084995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60063267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8232779] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93500775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5177865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.846763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.880855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9183763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.608666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0489448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7041797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5733807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73293304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8272968] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9103196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82597303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0185916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97402036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6808129] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77569056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72735465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.754567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7140537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7784479] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6993366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9022994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8706474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93187225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76025873] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7168303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66728044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7465571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8223258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78455615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9378785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7756521] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85537493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.652652] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7479981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6133118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8791114] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57097286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81412685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6077355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5741445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0714825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79717267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9351273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6401121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7996903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7188053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6862424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7522018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7047969] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68137956] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6809362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82528937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70697474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7994328] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6361085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7039842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77867275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.684536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8839533] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9358367] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9740015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78982383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62264436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98028904] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7261236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76572067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8605412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67499447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0388284] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7211011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63428116] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72442234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0934848] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7978268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88091606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.889494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93819606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60091996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8237264] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8314571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.721184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6858155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77840453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67773384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63508767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52643377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7152625] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8352069] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98284394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0750042] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8033651] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92831576] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7211438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75201637] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7247162] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83672035] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58248043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7080319] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7334145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7166672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76247585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51826495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69753397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87473917] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8887548] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57954043] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6538671] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8696525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7420635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5683886] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8211256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9750265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9384029] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82709396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6375282] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6702866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93090844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90475655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8169222] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74094176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72948396] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1044431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8878238] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61747575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6219038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58337855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59981745] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7652565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76768655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.719994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7345416] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9222218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.728819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65926015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64839906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75962394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60724884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94248223] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73190475] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78143305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5387566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5623173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99127936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67922884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7972678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79510915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8451909] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7070939] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71517265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8721703] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7352037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71313435] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72749937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89685255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6577946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7819378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6861391] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7013139] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8463242] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5622513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.653101] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7363725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84331894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0696436] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9027378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6689171] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6947819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6410842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77373785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.689844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64869934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75669074] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1337228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59273946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95526934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.781914] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62050414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8882158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62414616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72016907] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.017037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57279366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72913694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89109004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7209897] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93086797] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79003656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77303845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6428552] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6173919] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7390933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6884027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85991085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93094414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.691107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.883179] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53195786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9475806] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86565936] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6003196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.202689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6631109] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1274134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6304369] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88713187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6973203] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99570835] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79843295] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65423596] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75850296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9937762] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0184339] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6992353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6611923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81855017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64310455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87487084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7159639] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7966185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6566784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9042772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8539795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0393481] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84728813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5840814] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6614817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65747356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76773673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1397107] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7738459] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6978928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92888075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7491038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1721077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0783979] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73086303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9570259] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6845243] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79156506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90123385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7092751] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.831714] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75341624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67986757] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6477089] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6958617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5346292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7413632] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7001411] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67331314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72805274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57591087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7461968] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9507359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6028485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6010188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84247553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69197667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90249366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.187359] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5403829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.47107804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72879404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6474587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60041493] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6720574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9313389] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2709368] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1347451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84907943] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59374684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0111282] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2528683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9351736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5983461] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88377213] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8196473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7792075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.183737] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61248296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7269187] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63565725] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55279076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8464399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7013568] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1185744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87144345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7801337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6311218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87000483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7415439] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52654445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7323525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7736321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5862993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74928695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9215573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7486627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60008925] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8397088] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82091683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6878325] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7260303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.745199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.928931] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8012937] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7045638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8488746] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5924836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7372781] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0709804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7690889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5998121] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0052471] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6362414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.608634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9788003] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70027196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8297438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5504663] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6700164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7152454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.787683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9115368] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7625334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7765033] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7940278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77891636] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0542027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6709906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95016485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69422984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5560414] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6619803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6044933] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7272946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0052397] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9688472] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91911924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73348415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7154546] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7251427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89749587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48417014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8472571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8462212] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8520633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69106245] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7984008] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92033195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0536889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87246996] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6611256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7522317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8820938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8072796] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82883054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77423334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7525701] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7738638] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6185726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5763096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7915167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93631715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95252407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.920027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76240337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81876516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6041361] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78452563] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71717876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1647464] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7909291] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7681604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91997695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81003076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9108199] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8652795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94351286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7178993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7319106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61936605] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8532808] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7979613] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7807532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85842425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63851196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7692774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86550134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.714431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88287425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60551924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8162743] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6829177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57026535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83325726] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7358106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6312331] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75238246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82135946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8055318] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7093317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67136407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7594216] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4845048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0350705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80627126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6424017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9730536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0010258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61830366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.639532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9379573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93623316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71059525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85448426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81551534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7811845] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6624063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63913196] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68023616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1608993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8565126] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.527378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9928711] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66709304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94717574] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74906594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60755426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0535672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78897977] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6914055] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9927175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86189014] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6601813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7979665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6234291] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5528316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73161924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0067903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5644826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8451364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90558004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.774821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68383384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61790824] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81671166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6964536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1974915] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8029739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8317466] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7048626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.753349] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6309544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63612837] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99092525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52726173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0144246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74079597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9079689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9297073] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61833036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69186723] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6759616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8859532] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64050674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8901584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7861545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5948479] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1567597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8798188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8389537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81298] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7769351] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7733846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7286434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7412764] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.973771] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84310484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84047455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66917604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76763815] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6123066] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0559803] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1682553] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1765811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6782141] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7094989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67993057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82801294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78393155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71153575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6746267] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0221891] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91859585] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7830162] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59436053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73089045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91189945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6714158] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9082372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6331128] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6524813] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0985246] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.635406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7647856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73442984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6471037] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6918204] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84143984] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72036254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82832056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7491266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7678503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7537582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61674696] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60626775] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1152349] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68449736] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0475802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8877408] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6930077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6122465] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96931916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8469981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9485598] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6802283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8066315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8061959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5367346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56264913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8093829] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9152821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8596051] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72851753] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.915188] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65180695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75259244] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77201194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5996323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63694537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6986593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8438201] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63186324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83800125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7579788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0250506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9208152] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6466484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0006105] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63076913] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57326317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62120575] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5271348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75088525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0007226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7461195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7494002] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8043362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6500093] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68427944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.988064] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8812027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6681527] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6412684] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1182498] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8533777] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72564155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6752621] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67955375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5965036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55392003] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59589094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7670293] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1855314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66927] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8193377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7464658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5389712] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5093763] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2106857] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8587255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7470739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8282548] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0981629] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8365405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52137715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.3404398] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5404685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87351215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6833792] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8626143] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0119151] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85475767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65002805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5822782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9888512] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8983825] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5724807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79909265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9453053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74214536] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6066072] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0143167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7011558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6773044] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9583326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7212266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57748616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7883025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6412145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7471413] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9657922] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8236106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85536146] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7064654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0112082] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68417335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72135866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8823898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8069648] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75769657] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97959054] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84211665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81215644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9155473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66875875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7702038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79160225] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75878334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71975744] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88114667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7944166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9495198] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6491588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5931761] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8923479] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.95886666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77000827] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6767125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7213458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82802385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8000458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6336998] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73167235] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82941484] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6728877] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80383795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7494683] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6791658] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0777674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8954542] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8186469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6534953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7614255] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6514741] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66931874] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89984095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8174176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73523945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9523424] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8624781] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70582855] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96365523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73648506] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7887463] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56886643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.748193] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7709836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7675426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6734995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69375217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8689712] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79025954] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.617053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83113176] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67729425] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7020865] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8585283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86990154] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0018519] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64483315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7922338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68439525] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82148963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72347677] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7151352] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68758535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9775959] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80341923] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53473395] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.45052633] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7083366] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6416022] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8657513] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7429183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6548233] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7867496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78202844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75371635] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67760724] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87803346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6469784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7170268] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.715584] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68251336] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84084916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0099612] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7437337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7172548] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63603836] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73691523] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6974357] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8058864] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8958789] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.939362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6203989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81683755] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6159153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67815363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82423544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1909021] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6047355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74925345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8392872] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76083004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9624981] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6531278] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.845099] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6406326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6444659] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65462047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53283817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8856433] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6938707] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74581987] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6446701] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71942383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5955924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99244094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7823068] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64811474] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7575991] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0877705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7021634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.784166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6041119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76039565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9641995] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7305039] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0326085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67252934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0578634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68839085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0208819] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9142572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7194321] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0077189] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76885307] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67069453] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62743807] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6816379] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0173383] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99962944] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8202445] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5492009] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92008483] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71691734] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9626218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91322786] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6621075] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6294221] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72142804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7601265] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99930084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8045994] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5099718] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57958555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.890985] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1792549] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69563067] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7879032] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81977415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66681504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69003314] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82435495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57574236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7723253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7292434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8501771] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7071388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6721674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8770728] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78509283] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8790123] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7832791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96685076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7200019] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.674404] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6381935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61255324] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8320571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56585544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7265361] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6455291] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63547224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0014852] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.90635157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68382955] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6890175] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62052315] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7732721] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7314795] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78328896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79083693] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65218997] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7045218] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71819437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7458048] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59768647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73337376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6898375] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7911235] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70047843] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6104088] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6461017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83885217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5949117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5818311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64268804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56843376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72549593] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0426921] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7770958] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8704291] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0431589] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8714641] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78893656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7861007] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85946226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79516214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7319447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79311323] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7807346] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9053812] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92488134] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7070155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97434145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7836266] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91189384] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7770405] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64211446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6214582] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87734455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62388194] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5027678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9591399] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.749932] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4702379] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9119164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7867924] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7745689] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6339531] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.839564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7634297] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6535219] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48589316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7991643] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.574118] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5487026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7896029] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9080878] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9919449] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86747885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.644776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8297808] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.74899185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9066157] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7771296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67416817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58667165] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77924967] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6026999] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7361962] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83747894] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49762645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82522666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98099387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71628785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7592557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7298017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5816084] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0185382] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8712671] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8963344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7508545] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92156094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75380945] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86432767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69347227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.083096] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.96990377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9205934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8390717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89014983] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64119065] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8108847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6712782] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6140449] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63990587] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6646438] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7271125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78659713] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8270809] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72137624] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97613496] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9395228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5880672] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7671678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7711053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6699898] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8963482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6348122] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9080117] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6659805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6152004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83730304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65780973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6254356] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9312095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61460555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9404454] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99590296] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6976862] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8331885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8509504] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5841588] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80568767] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70296013] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82174885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83976597] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5019451] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6386119] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8171606] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.80912805] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8418426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89569294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6052878] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9345519] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.838482] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61300653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8803674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76725495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93423337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7867363] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68947685] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88964236] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7196386] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5194063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5182487] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7416673] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9462946] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7092372] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6040659] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.91013986] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8527083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6922665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83478653] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92065036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6020448] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70896024] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7630567] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9411537] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73185086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63623136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0236304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5682854] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62902] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8080467] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6909049] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85117215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6985712] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7627125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.867772] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79467106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7292778] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76426876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6497494] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5419716] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.49618623] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7928938] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8109832] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6867136] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88425237] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5989963] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81807816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9330138] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5143866] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8467812] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87855047] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9141299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6082247] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0438125] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7016572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5744311] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.727928] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.82895166] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.903327] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8206921] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0148431] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97098434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68004113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77316666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7226254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7552282] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.713132] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7780229] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6958549] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89567214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8679821] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9288529] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7614202] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71598774] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66296333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7445299] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8183028] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78135616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9314571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77485317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8519939] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6503521] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7483802] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61280906] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87605333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5696682] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8107112] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6065856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57374305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0697254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79385185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93640655] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63941234] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.792642] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7159115] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68053156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7460227] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7016719] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6801317] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67941856] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.823335] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70426226] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8009627] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6336238] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6976446] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77262473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68396306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8785212] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93169415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9738941] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78838974] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6233649] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.978273] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72523564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7578442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8544205] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6737558] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.033304] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7146177] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6303447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72169274] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0877947] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7943852] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87774485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88891476] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9294127] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5978731] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8219191] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8250427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7189046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6854447] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77902544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6730645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6315528] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52162427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7134301] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83420086] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.97991645] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0708455] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8028538] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92575437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7214155] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7498555] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72406876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8339163] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.57932013] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7046442] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7321818] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7152469] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75790167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.51512057] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69506407] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8729444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8916289] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5751965] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6507072] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8673717] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73993903] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5678964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8178776] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9717241] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93599665] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8206097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6338884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6663228] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92447853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9013688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81744885] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.737879] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72561616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0962061] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88110006] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6146694] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6220876] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58137816] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59688604] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.760617] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75989294] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7195011] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7317063] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9158025] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72453594] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6573106] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64562345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7596666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6043849] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.93542564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7274654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7791085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.53243345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5606552] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.98473334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.67673784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7949591] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7926113] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8408326] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70463765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7128688] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86135256] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73399615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71036094] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72358286] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8899788] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65353036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7801492] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68324167] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6932458] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8413572] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5628248] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6494292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.73385] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83844316] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0649253] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.89595765] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71607834] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66690916] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69530153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6398082] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76927185] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6839144] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6468853] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75475174] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1304508] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5875811] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9525817] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77943355] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8846344] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6234077] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7158485] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0162418] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.56999034] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72957844] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.88708544] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71713644] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.929097] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7850842] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76970524] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63991535] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61210376] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7345345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6866029] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8548027] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9285184] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68610257] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8803078] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5304214] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94563437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86614573] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59869444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1930102] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6594516] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1248611] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62838495] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8824551] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69257164] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9917083] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79691565] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64979017] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75662804] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.99610656] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0095046] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69415534] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6598739] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.81869847] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63915557] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8702388] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71077526] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.79382217] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65685964] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9017785] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.85139394] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0344292] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84720415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58272016] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66162634] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65457875] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.76395667] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1367884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7699337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69476444] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9250686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7460631] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1677338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0761564] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72647345] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9513172] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68418896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.78373015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9007001] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71006966] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8260348] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7514556] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6760666] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.64730173] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6936858] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5322378] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7346503] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69799626] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6699647] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72308654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.575087] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7431362] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94246364] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.59619004] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.598603] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83658826] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6892258] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.70031095] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8978678] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1875569] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5362056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.4669038] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72809434] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6429473] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6012036] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.665911] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92885303] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2681012] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1327202] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8479895] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5896756] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0079079] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.2440674] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9339338] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5935761] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8805988] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8156686] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77574754] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1791784] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.61286783] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.72201437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63462377] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5512884] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.83805615] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69561833] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.1140561] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8655215] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7806571] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.62497085] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.86635935] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7384989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.52539] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7287695] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7696305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5837521] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7419705] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9228654] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7461846] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5994254] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8360621] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.816224] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.68654275] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7215391] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7392896] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.92391306] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7958715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7062868] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8422053] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.58963156] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7359883] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0704333] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7719859] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5949145] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0021183] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.63518566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6064543] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9742415] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6961018] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8281791] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.5481353] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.66750056] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7109566] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7862993] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9098929] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.75743973] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7774511] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7884076] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.77714616] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0490427] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6674489] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.94740045] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.6892412] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.55565387] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.65796953] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.60354334] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7272437] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.0024153] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9657422] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9141978] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7311195] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.71033305] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.7247889] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8958989] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.48056406] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84333026] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.84127426] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.8489337] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.69167715] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.794015] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.9131104] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [1.054934] \n",
      "After  0 training   step(s)   ,   loss    on    training    batch   is  [0.87411267] \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    global_step = tf.Variable(0,trainable=False)\n",
    "    trainx, trainy, trainx_field = gen_data()\n",
    "    # 定义输入\n",
    "    input_x = tf.placeholder(tf.float32,[input_x_size ])\n",
    "    input_y = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 正则项的系数\n",
    "    lambda_w = tf.constant(0.001, name='lambda_w')\n",
    "    lambda_v = tf.constant(0.001, name='lambda_v')\n",
    "\n",
    "    zeroWeights = create0dim_weight(input_x_size)\n",
    "\n",
    "    oneDimWeights = create1dim_weight(input_x_size)\n",
    "\n",
    "    thirdWeight = create2dim_weight(input_x_size,  # 创建二次项的权重变量\n",
    "                                    field_size,\n",
    "                                    vector_dimension)  # n * f * k\n",
    "\n",
    "    y_ = inference(input_x, trainx_field,zeroWeights,oneDimWeights,thirdWeight)\n",
    "\n",
    "    l2_norm = tf.reduce_sum(\n",
    "        tf.add(\n",
    "            tf.multiply(lambda_w, tf.pow(oneDimWeights, 2)),\n",
    "            tf.reduce_sum(tf.multiply(lambda_v, tf.pow(thirdWeight, 2)),axis=[1,2]) ## 对第1和第2维进行求和处理，最终时期变成1dim\n",
    "        )\n",
    "    )\n",
    "\n",
    "    loss = tf.log(1 + tf.exp(-input_y * y_)) + l2_norm\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(total_plan_train_steps):\n",
    "            for t in range(all_data_size):\n",
    "                input_x_batch = trainx[t]\n",
    "                input_y_batch = trainy[t]\n",
    "                predict_loss,_, steps = sess.run([loss,train_step, global_step],\n",
    "                                               feed_dict={input_x: input_x_batch, input_y: input_y_batch})\n",
    "\n",
    "                print(\"After  {step} training   step(s)   ,   loss    on    training    batch   is  {predict_loss} \"\n",
    "                      .format(step=steps, predict_loss=predict_loss))\n",
    "\n",
    "                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=steps)\n",
    "                writer = tf.summary.FileWriter(os.path.join(MODEL_SAVE_PATH, MODEL_NAME), tf.get_default_graph())\n",
    "                writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
